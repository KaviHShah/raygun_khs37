{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f248b1-3d9c-46bd-accc-7bdb87dfaf23",
   "metadata": {},
   "source": [
    "# Prototyping Model 0 - Raygun implemented in notebook form - for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50bfdc6c-19bc-4b2f-95ae-b46046ae5668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm \n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from esm.model.esm2 import TransformerLayer\n",
    "from einops import rearrange, reduce\n",
    "from einops import repeat, rearrange, reduce\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# Dataloader: \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import esm\n",
    "from glob import glob\n",
    "import h5py \n",
    "#from tqdm import tqdm\n",
    "import re\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import os\n",
    "#import torch\n",
    "#from einops import rearrange\n",
    "from Bio import SeqIO\n",
    "\n",
    "#Lightning_model_wrapper\n",
    "import lightning as L\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "from Bio.Align import substitution_matrices\n",
    "import numpy as np\n",
    "\n",
    "#Train\n",
    "import argparse\n",
    "#from raygun.pretrained import raygun_4_4mil_800M\n",
    "import yaml\n",
    "#from torch.utils.data import DataLoader\n",
    "#from tqdm import tqdm\n",
    "#import torch.nn.functional as F\n",
    "#import torch.nn as nn\n",
    "#import numpy as np\n",
    "#import torch\n",
    "#import esm\n",
    "#import os\n",
    "#import pandas as pd\n",
    "import itertools\n",
    "import time\n",
    "import json\n",
    "#from Bio.Align import substitution_matrices\n",
    "import subprocess\n",
    "import logging \n",
    "#import lightning as L\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "#from raygun.modelv2.esmdecoder import DecoderBlock\n",
    "#from raygun.modelv2.model_utils import Block, BlockP\n",
    "#from raygun.modelv2.reduction import Reduction\n",
    "#from raygun.modelv2.repetition import Repetition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa1f366-b39e-4864-8d90-cb99c50954bd",
   "metadata": {},
   "source": [
    "# Hydra for managing config and parameter screens , would add a hubconf file for models\n",
    "\n",
    "I am possibly going to move this after defining the model - we will see which is clearer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9198c6d-3f5f-4a91-a86a-22677f3dfe91",
   "metadata": {},
   "source": [
    "# Torch model (torch.nn)\n",
    "\n",
    "The model will be made of an encoder and decoder. \n",
    "\n",
    "I will try and order the modules used in order they are being used - obviously they do not have to be used in that order - but this is just for my clarity. Some have multiple versions that I have written that you could choose between.\n",
    "\n",
    "The architecture is an auto encoder model. This has an architecture where embeddings are generated and compressed (encoder) and decompressed and verified against the original (decoder). \n",
    "\n",
    "note for me - this is different to autoregressive decoder - for clarity for myself - autoencoder decoder. \n",
    "\n",
    "To see Ragun v2's architecture summary run:\n",
    "\n",
    "```\n",
    "from raygun.pretrained import raygun_2_2mil_800M\n",
    "# \n",
    "raymodel = raygun_2_2mil_800M()\n",
    "#raymodel = raymodel.to(0)\n",
    "raymodel.eval()\n",
    "\n",
    "```\n",
    "\n",
    "Hyperparameters are here: https://github.com/rohitsinghlab/raygun/blob/main/hubconf.py - in the hubconf e.g. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fdbac2a-b8ed-4a48-ad7e-38981a36a287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /hpc/home/khs36/.cache/torch/hub/rohitsinghlab_raygun_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://zenodo.org/records/15447158/files/model-may-16.ckpt?download=1\" to /hpc/home/khs36/.cache/torch/hub/checkpoints/model-may-16.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.10G/3.10G [02:23<00:00, 23.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Raygun(\n",
       "  (encoder): RaygunEncoder(\n",
       "    (encoders): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (encoder): TransformerLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (rot_emb): RotaryEmbedding()\n",
       "          )\n",
       "          (self_attn_layer_norm): ESM1LayerNorm()\n",
       "          (fc1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "          (fc2): Linear(in_features=2560, out_features=1280, bias=True)\n",
       "          (final_layer_norm): ESM1LayerNorm()\n",
       "        )\n",
       "        (convblock): ConvBlock(\n",
       "          (c1): ConvMasked(\n",
       "            (conv): Conv1d(1280, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
       "          )\n",
       "          (s1): SiLU()\n",
       "          (c2): ConvMasked(\n",
       "            (conv): Conv1d(640, 320, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "          )\n",
       "          (s2): SiLU()\n",
       "          (c3): ConvMasked(\n",
       "            (conv): Conv1d(320, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
       "          )\n",
       "          (s3): SiLU()\n",
       "        )\n",
       "        (final): Linear(in_features=640, out_features=1280, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (reduction): Reduction()\n",
       "    (final): Sequential(\n",
       "      (0): Linear(in_features=16640, out_features=392, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=392, out_features=1280, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): RaygunDecoder(\n",
       "    (dbefore): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (encoder): TransformerLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (rot_emb): RotaryEmbedding()\n",
       "          )\n",
       "          (self_attn_layer_norm): ESM1LayerNorm()\n",
       "          (fc1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "          (fc2): Linear(in_features=2560, out_features=1280, bias=True)\n",
       "          (final_layer_norm): ESM1LayerNorm()\n",
       "        )\n",
       "        (convblock): ConvBlock(\n",
       "          (c1): ConvMasked(\n",
       "            (conv): Conv1d(1280, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
       "          )\n",
       "          (s1): SiLU()\n",
       "          (c2): ConvMasked(\n",
       "            (conv): Conv1d(640, 320, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "          )\n",
       "          (s2): SiLU()\n",
       "          (c3): ConvMasked(\n",
       "            (conv): Conv1d(320, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
       "          )\n",
       "          (s3): SiLU()\n",
       "        )\n",
       "        (final): Linear(in_features=640, out_features=1280, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (repetition): Repetition()\n",
       "    (dafter): ModuleList(\n",
       "      (0-12): 13 x Block(\n",
       "        (encoder): TransformerLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (rot_emb): RotaryEmbedding()\n",
       "          )\n",
       "          (self_attn_layer_norm): ESM1LayerNorm()\n",
       "          (fc1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "          (fc2): Linear(in_features=2560, out_features=1280, bias=True)\n",
       "          (final_layer_norm): ESM1LayerNorm()\n",
       "        )\n",
       "        (convblock): ConvBlock(\n",
       "          (c1): ConvMasked(\n",
       "            (conv): Conv1d(1280, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
       "          )\n",
       "          (s1): SiLU()\n",
       "          (c2): ConvMasked(\n",
       "            (conv): Conv1d(640, 320, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "          )\n",
       "          (s2): SiLU()\n",
       "          (c3): ConvMasked(\n",
       "            (conv): Conv1d(320, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
       "          )\n",
       "          (s3): SiLU()\n",
       "        )\n",
       "        (final): Linear(in_features=640, out_features=1280, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (final): Sequential(\n",
       "      (0): Linear(in_features=17920, out_features=364, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=364, out_features=1280, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (esmdecoder): DecoderBlock(\n",
       "    (encoder): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): ESM1LayerNorm()\n",
       "      (fc1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "      (fc2): Linear(in_features=2560, out_features=1280, bias=True)\n",
       "      (final_layer_norm): ESM1LayerNorm()\n",
       "    )\n",
       "    (final): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=320, bias=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=320, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from raygun.pretrained import raygun_2_2mil_800M\n",
    "# \n",
    "raymodel = raygun_2_2mil_800M()\n",
    "#raymodel = raymodel.to(0)\n",
    "raymodel.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e6a4b8-5f1c-460b-addd-0e2c6365a35c",
   "metadata": {},
   "source": [
    "## Encoder parts:\n",
    "\n",
    "### The first step is ESM2 - we take the final transformer layer embedding as input to the raygun step\n",
    "\n",
    "ESM2 is itself an encoder only PLM, trained by meta. Its architecture summary is outputted in the cell below. It is trained using masking. i.e. residues are hidden and the model enters the correct ones. By doing this it must have some understanding (model) of both protein structure and function. From this as a base many further models have been generated. \n",
    "\n",
    "\n",
    "The first step - both tokenisation after which going through the layers generates the embedding. For our use, we take the final layer (see the data loader) output of ESM2 as the start for our encoder. Note that it uses rotary embeddings and multihead attention. Following this Raygun original currently does use the ESM2 architecture (not the model itself or weights - but the defined Transformer Layer architecture in the first step of Rayguns encoder - with 12 heads - I may change it - let's see\n",
    "\n",
    "# Where this ESM step is in the Raygun code \n",
    "\n",
    "For the tokenising and generating embeddings step itself it is only seen in the DataLoader of the Raygun - and so in the loader.py in model version2 and then in the command in train - it outputs an embedding size \n",
    "\n",
    "```\n",
    "## train and validation loaders\n",
    "    traindata = RaygunData(fastafile = config[\"trainfasta\"],\n",
    "                           alphabet  = esmalphabet,\n",
    "                           model     = esmmodel, \n",
    "                           device    = 0)\n",
    "```\n",
    "\n",
    "In the dataloader: self.bc        = self.alphabet.get_batch_converter()\n",
    "this is esm.data.Alphabet class\n",
    "\n",
    "This method is part of the ESM model loading utilities, and it's used to convert raw protein sequences into token IDs that the ESM transformer can understand.\n",
    "\n",
    "# See S1 Aside - attention and multihead attention\n",
    "\n",
    "See aside copied from the script where I was learning about that.\n",
    "\n",
    "\n",
    "# See S2 Aside - rotary pos embeddings\n",
    "\n",
    "See aside copied from the script where I was learning about that.\n",
    "\n",
    "\n",
    "### Contact head bit\n",
    "\n",
    "Note contact_head prediction uses the embedding generated (last layer) to predict contacts - pairs are turned into 1 or 0 - this indicates 3D structure - Note double check to see if this explanation is correct\n",
    "\n",
    "From Gemini: \n",
    "\n",
    "regression: Linear(in_features=660, out_features=1, bias=True): A linear layer transforms the pair-wise feature into a single raw score.\n",
    "\n",
    "activation: Sigmoid(): The sigmoid function squashes the score into a value between 0 and 1, which can be interpreted as the probability that the two protein residues are in contact.\n",
    "\n",
    "### embed layer norm\n",
    "\n",
    ". emb_layer_norm_after: LayerNorm\n",
    "\n",
    "Role: This is a final Layer Normalization step applied to the entire output sequence of hidden states from the last of the 33 TransformerLayer modules.\n",
    "\n",
    "Mechanism: It normalizes the activation of the final output embeddings (dimension 1280) across the features (the hidden dimension). This helps in stabilizing the distribution of the embeddings before they are consumed by the final prediction heads (contact_head and lm_head).\n",
    "\n",
    "### lm_head: RobertaLMHead\n",
    "\n",
    "Gemini:\n",
    "\n",
    "Role: This head is responsible for the Language Modeling (LM) task, which, for ESM2, is primarily the Masked Amino Acid Prediction task it was trained on (similar to the original RoBERTa or BERT models). This allows the model to predict the identity of masked-out amino acids in a sequence.\n",
    "\n",
    "Mechanism:\n",
    "\n",
    "dense: Linear(in_features=1280, out_features=1280, bias=True): A feed-forward layer to further process the 1280-dimensional hidden states.\n",
    "\n",
    "layer_norm: LayerNorm((1280,), eps=1e-05, elementwise_affine=True): Another normalization step applied to the processed hidden states.\n",
    "\n",
    "Implicit Final Linear Layer: The provided snippet doesn't show the very last layer, but an LM Head typically has a final linear projection (often tied to the embedding weights) that maps the 1280-dimensional hidden state back to the size of the vocabulary (33 in this case: 20 standard amino acids + B, Z, X, U, O, J, start, end, padding, mask). The output is a set of logits over the vocabulary for each position in the sequence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c7f93bf-6e3c-4665-951f-c41a5143813a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESM2(\n",
       "  (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "  (layers): ModuleList(\n",
       "    (0-32): 33 x TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (contact_head): ContactPredictionHead(\n",
       "    (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       "  (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from esm.pretrained import esm2_t33_650M_UR50D\n",
    "\n",
    "esm2model, alph = esm2_t33_650M_UR50D()\n",
    "\n",
    "esm2model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ff2fe-5a0f-4410-9588-3a808624af5a",
   "metadata": {},
   "source": [
    "# After the ESM2 embedding step - I can do multi-mixing etc. before the raygun reduction step\n",
    "\n",
    "# After raygun full encoder (e.g. on the two parts separately - I can then do the mixing etc. and more layers before using the decoder architecture from raygun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314612b1-914c-488c-9c4f-86e98eb5a4eb",
   "metadata": {},
   "source": [
    "# Step 1: Encoder - The first step of the two main step encoder is defined in the Block class\n",
    "```\n",
    "(0-11): 12 x Block(\n",
    "        (encoder): TransformerLayer(\n",
    "          (self_attn): MultiheadAttention(\n",
    "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "            (rot_emb): RotaryEmbedding()\n",
    "          )\n",
    "          (self_attn_layer_norm): ESM1LayerNorm()\n",
    "          (fc1): Linear(in_features=1280, out_features=2560, bias=True)\n",
    "          (fc2): Linear(in_features=2560, out_features=1280, bias=True)\n",
    "          (final_layer_norm): ESM1LayerNorm()\n",
    "        )\n",
    "        (convblock): ConvBlock(\n",
    "          (c1): ConvMasked(\n",
    "            (conv): Conv1d(1280, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
    "          )\n",
    "          (s1): SiLU()\n",
    "          (c2): ConvMasked(\n",
    "            (conv): Conv1d(640, 320, kernel_size=(3,), stride=(1,), padding=valid)\n",
    "          )\n",
    "          (s2): SiLU()\n",
    "          (c3): ConvMasked(\n",
    "            (conv): Conv1d(320, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
    "          )\n",
    "          (s3): SiLU()\n",
    "        )\n",
    "        (final): Linear(in_features=640, out_features=1280, bias=True)\n",
    "      )\n",
    "    )\n",
    "```\n",
    "\n",
    "This is the first part of the class Raygun Encoder:\n",
    "```\n",
    "        self.encoders = nn.ModuleList()\n",
    "        for i in range(numencoders):\n",
    "            self.encoders.append(Block(dim = dim, \n",
    "                                       convkernel = convkernel, \n",
    "                                       attnheads = nhead))\n",
    "\n",
    "```\n",
    "This is implemented in Block which is stored in model_utils\n",
    "\n",
    "This is composed of a normal layer from ESM2 , followed by a convolutional block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce190f9-a4fc-4bd2-a6d7-4b9e2ee24557",
   "metadata": {},
   "source": [
    "# The TransformerLayer function is from ESM2: It has this structure: \n",
    "\n",
    "```\n",
    "class TransformerLayer(nn.Module):\n",
    "    \"\"\"Transformer layer block.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim,\n",
    "        ffn_embed_dim,\n",
    "        attention_heads,\n",
    "        add_bias_kv=True,\n",
    "        use_esm1b_layer_norm=False,\n",
    "        use_rotary_embeddings: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ffn_embed_dim = ffn_embed_dim\n",
    "        self.attention_heads = attention_heads\n",
    "        self.use_rotary_embeddings = use_rotary_embeddings\n",
    "        self._init_submodules(add_bias_kv, use_esm1b_layer_norm)\n",
    "\n",
    "    def _init_submodules(self, add_bias_kv, use_esm1b_layer_norm):\n",
    "        BertLayerNorm = ESM1bLayerNorm if use_esm1b_layer_norm else ESM1LayerNorm\n",
    "\n",
    "        self.self_attn = MultiheadAttention(\n",
    "            self.embed_dim,\n",
    "            self.attention_heads,\n",
    "            add_bias_kv=add_bias_kv,\n",
    "            add_zero_attn=False,\n",
    "            use_rotary_embeddings=self.use_rotary_embeddings,\n",
    "        )\n",
    "        self.self_attn_layer_norm = BertLayerNorm(self.embed_dim)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.embed_dim, self.ffn_embed_dim)\n",
    "        self.fc2 = nn.Linear(self.ffn_embed_dim, self.embed_dim)\n",
    "\n",
    "        self.final_layer_norm = BertLayerNorm(self.embed_dim)\n",
    "\n",
    "    def forward(\n",
    "        self, x, self_attn_mask=None, self_attn_padding_mask=None, need_head_weights=False\n",
    "    ):\n",
    "        residual = x\n",
    "        x = self.self_attn_layer_norm(x)\n",
    "        x, attn = self.self_attn( \n",
    "            query=x,\n",
    "            key=x,\n",
    "            value=x,\n",
    "            key_padding_mask=self_attn_padding_mask,\n",
    "            need_weights=True,\n",
    "            need_head_weights=need_head_weights,\n",
    "            attn_mask=self_attn_mask,\n",
    "        )\n",
    "        x = residual + x\n",
    "### note what the above is doing I think is pulling new embedding from ESM1LayerNorm for attention then adding that to the output of the previous layer to then output to the subsequent layer.\n",
    "\n",
    "        residual = x\n",
    "        x = self.final_layer_norm(x)\n",
    "        x = gelu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = residual + x\n",
    "\n",
    "        return x, attn\n",
    "```\n",
    "It can be seen printed within the Block \n",
    "\n",
    "* Note here just using the ESM2 architecture rather than having to define our own\n",
    "\n",
    "ESM output: (batch_size, sequence_length, embedding_dim) b n c\n",
    "I think when in batch - pads to a fixed length - maybe of the shortest dim / fixed length not sure) - then masks. - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "573256c8-2480-4eaf-b448-9675d842e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, dim = 2560, attnheads = 5, convkernel = 7):\n",
    "        super(Block, self).__init__()\n",
    "        self.encoder = TransformerLayer(embed_dim = dim, \n",
    "                                       ffn_embed_dim = 2 * dim,\n",
    "                                       attention_heads = attnheads,\n",
    "                                       use_rotary_embeddings = True)\n",
    "        \n",
    "        self.convblock = ConvBlock(dim, convkernel)\n",
    "        self.final = nn.Linear(dim // 2, dim)\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        x    = rearrange(x, \"b n c -> n b c\") #changes so now (sequence_length, batch_dim, embedding_dim)\n",
    "        x, _ = self.encoder(x, self_attn_padding_mask = ~mask if mask is not None else mask) # likely mask.shape == (batch_size, seq_len)) - check mask is 0 or not\n",
    "        x    = rearrange(x, \"n b c -> b n c\")\n",
    "\n",
    "        x    = self.convblock(x, mask = mask)\n",
    "        \n",
    "        return self.final(x)\n",
    "\n",
    "# the above calls the ConvBlock function - block is built on Convblock\n",
    "\n",
    "# Convblock is itself built on ConvMasked\n",
    "# Convolution is essentially a low pass filter - here it must help extract important features\n",
    "# See aside below for notes\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, dim, convkernel):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.c1 = ConvMasked(dim     , dim // 2, kernel_size=convkernel)\n",
    "        self.s1 = nn.SiLU()\n",
    "        self.c2 = ConvMasked(dim // 2, dim // 4, kernel_size=convkernel // 2)\n",
    "        self.s2 = nn.SiLU()\n",
    "        self.c3 = ConvMasked(dim // 4, dim // 2, kernel_size=convkernel)\n",
    "        self.s3 = nn.SiLU()\n",
    "        return\n",
    "    \n",
    "    def forward(self, x, mask = None): \n",
    "        x = rearrange(x, \"b n c -> b c n\")\n",
    "        if mask is not None:\n",
    "            x = x * mask.unsqueeze(1)\n",
    "        x = self.s1(self.c1(x, mask)) # uses SiLU activation functions, \n",
    "        x = self.s2(self.c2(x, mask))\n",
    "        x = self.s3(self.c3(x, mask))\n",
    "        x = rearrange(x, \"b c n -> b n c\") \n",
    "        return x\n",
    "\n",
    "class ConvMasked(nn.Module):\n",
    "    \"\"\"\n",
    "    Applied modifications on Conv1d to make the masking work\n",
    "    \"\"\"\n",
    "    def __init__(self, indim, outdim, kernel_size):\n",
    "        super(ConvMasked, self).__init__()\n",
    "        self.conv        = nn.Conv1d(indim, outdim, \n",
    "                                    kernel_size = kernel_size, padding = \"valid\") #same as padding=0\n",
    "        self.kernel_size = kernel_size\n",
    "        self.indim       = indim\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        batch, _, _ = x.shape\n",
    "        padding = torch.zeros(batch, self.indim, self.kernel_size - 1).to(x.device)\n",
    "        x1      = torch.concat([x, padding], dim = 2) \n",
    "        # This is right padding - when using autoregression you want left padding/ causal time etc., \n",
    "        #not sure why right padding? - I think it is possibly to keep masking along the padding note I think b c n is the format\n",
    "        # or could be to correct for the uneven weighting of start vs enf \"pad\" if doesn't divide by 50 \n",
    "        # For mine -think about convolution state\n",
    "        y       =  self.conv(x1)\n",
    "        if mask is not None:\n",
    "            y   = y * mask.unsqueeze(1) # unsqueeze the seequence part\n",
    "        return y\n",
    "        #to reduce edge bias - might be better to do padding='same' rather than the custom padding bit\n",
    "        # note that default stride = 1\n",
    "        # Get someone to explain the reason raygun does this\n",
    "\n",
    "        # note ask about choice of input and output channels.\n",
    "\n",
    "#the weights in the Conv1d layers (ConvMasked) are initialized using PyTorch’s defaults, which follow the Kaiming Uniform (He Uniform) initialization scheme.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b747708a-19ee-4eb5-9210-a56f10a4409c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "536e11b6-3190-42fc-89fd-5a0948a4ef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block(\n",
      "  (encoder): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "      (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "      (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "      (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "      (rot_emb): RotaryEmbedding()\n",
      "    )\n",
      "    (self_attn_layer_norm): ESM1LayerNorm()\n",
      "    (fc1): Linear(in_features=2560, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=2560, bias=True)\n",
      "    (final_layer_norm): ESM1LayerNorm()\n",
      "  )\n",
      "  (convblock): ConvBlock(\n",
      "    (c1): ConvMasked(\n",
      "      (conv): Conv1d(2560, 1280, kernel_size=(7,), stride=(1,), padding=valid)\n",
      "    )\n",
      "    (s1): SiLU()\n",
      "    (c2): ConvMasked(\n",
      "      (conv): Conv1d(1280, 640, kernel_size=(3,), stride=(1,), padding=valid)\n",
      "    )\n",
      "    (s2): SiLU()\n",
      "    (c3): ConvMasked(\n",
      "      (conv): Conv1d(640, 1280, kernel_size=(7,), stride=(1,), padding=valid)\n",
      "    )\n",
      "    (s3): SiLU()\n",
      "  )\n",
      "  (final): Linear(in_features=1280, out_features=2560, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "block = Block()\n",
    "print(block)\n",
    "\n",
    "# If you look at the convolutions you seem to be ssquishing twice and then expanding once,\n",
    "# and then once more expanding in the final linear "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf02609-be23-42f1-9352-7a85140ddbe8",
   "metadata": {},
   "source": [
    "# Reduction and Final bits of the Encoder part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eada87-d237-40d5-b5d1-9103af868444",
   "metadata": {},
   "source": [
    "The final bits of the encoder function are to do the dimensionality reduction, \n",
    "- i.e. to fixed size representation followed by the last couple of layers.\n",
    "\n",
    "    (reduction): Reduction()\n",
    "    (final): Sequential(\n",
    "      (0): Linear(in_features=16640, out_features=392, bias=True)\n",
    "      (1): SiLU()\n",
    "      (2): Linear(in_features=392, out_features=1280, bias=True)\n",
    "    )\n",
    "  )\n",
    "\n",
    "This is in here:\n",
    "```\n",
    "class RaygunEncoder(nn.Module):\n",
    "    def __init__(self, dim = 1280, reduction = 50,\n",
    "                 convkernel = 7,\n",
    "                 nhead = 20, numencoders = 2, dropout = 0.2,\n",
    "                 activation = \"gelu\"):\n",
    "        super(RaygunEncoder, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.encoders = nn.ModuleList()\n",
    "        for i in range(numencoders):\n",
    "            self.encoders.append(Block(dim = dim, \n",
    "                                       convkernel = convkernel, \n",
    "                                       attnheads = nhead))\n",
    "\n",
    "\n",
    "        self.redlength = reduction\n",
    "        self.reduction = Reduction(reduce_size = reduction)\n",
    "\n",
    "-------------------------------------------------------------------------\n",
    "\n",
    "        self.final     = nn.Sequential(\n",
    "                            nn.Linear(dim * (numencoders+1), dim // (numencoders + 1) * 4),\n",
    "                            nn.SiLU(),\n",
    "                            nn.Linear(dim // (numencoders + 1) * 4, dim)\n",
    "                         )\n",
    "\n",
    "        nn.init.xavier_uniform_(self.final[0].weight, gain=1e-3)\n",
    "        nn.init.xavier_uniform_(self.final[2].weight, gain=1e-3)\n",
    "        nn.init.constant_(self.final[0].bias, 0)\n",
    "        nn.init.constant_(self.final[2].bias, 0)\n",
    "```\n",
    "\n",
    "You append the block outputs to a Module list (in this version of the model there are the initial embedding pluss 12 of them. If you look at the ESM encoder class you do that on the batch  - an then finally combine them in the self.final bit.\n",
    "\n",
    "The reduction process itself is self explanatory if you look at the function - I thought up a few possible alternatives - but they're not necessarily formatted to fit in.\n",
    "\n",
    "The inits - initialise the weights to very small values to start off with. (Apparently once there are existing weights stored - this code will be ignored. \n",
    "\n",
    "The reason this is here is to overwrite the default initialisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e746e2f6-3727-4041-94b8-707b7a7bb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raygun original reduction - this is in the encoder part\n",
    "class Reduction(nn.Module):\n",
    "    def __init__(self, reduce_size = 50, dim = 1280):\n",
    "        self.reduce_size = reduce_size\n",
    "        super(Reduction, self).__init__()\n",
    "        return\n",
    "    \n",
    "    def forward(self, x, mask = None, getstd = False):\n",
    "        \"\"\"\n",
    "        return the sigma of noise from x, in addition to the reduction\n",
    "        \"\"\"\n",
    "        batch, _, dim = x.shape\n",
    "\n",
    "        if mask == None:\n",
    "            ## batch, seqlen\n",
    "            mask = torch.ones_like(x[:, :, 0], dtype = int)\n",
    "        \n",
    "        seqs     = torch.sum(mask, dim = 1) \n",
    "        xmeans   = []\n",
    "        xstds    = []\n",
    "        for i in range(batch):\n",
    "            min_window_size  = seqs[i] // self.reduce_size\n",
    "            gap              = seqs[i] - min_window_size * self.reduce_size\n",
    "            gapleft          = gap // 2\n",
    "            gapright         = gap // 2\n",
    "            if gap % 2 == 1:\n",
    "                gapleft += 1\n",
    "            mid = self.reduce_size - gap\n",
    "            \n",
    "            firstbeg, firstend = 0, gapleft * (min_window_size + 1)\n",
    "            lastbeg, lastend   = seqs[i] - gapright * (min_window_size + 1), seqs[i]\n",
    "            midbeg, midend     = gapleft * (min_window_size + 1), gapleft * (min_window_size + 1) + mid * min_window_size\n",
    "        \n",
    "            xstart   = x[i, firstbeg:firstend, :].unsqueeze(0)\n",
    "            xmid     = x[i, midbeg:midend, :].unsqueeze(0)\n",
    "            xend     = x[i, lastbeg:lastend, :].unsqueeze(0)\n",
    "            \n",
    "            xstmean  = self.get_mean_std(xstart, min_window_size + 1, dim,\n",
    "                                                getstd, returnzero = (gapleft == 0), \n",
    "                                                device = x.device)\n",
    "            xmidmean = self.get_mean_std(xmid, min_window_size, dim,\n",
    "                                                    getstd, returnzero = False,\n",
    "                                                    device = x.device)\n",
    "            xendmean = self.get_mean_std(xend, min_window_size + 1, dim,\n",
    "                                                    getstd, returnzero = (gapright == 0),\n",
    "                                                    device = x.device)\n",
    "            if getstd:\n",
    "                xstmean, xststd   = xstmean\n",
    "                xmidmean, xmidstd = xmidmean\n",
    "                xendmean, xendstd = xendmean\n",
    "                xmean = torch.concat([xstmean, xmidmean, xendmean], dim = 1)\n",
    "                xstd  = torch.concat([xststd, xmidstd, xendstd], dim = 1)\n",
    "                xmeans.append(xmean)\n",
    "                xstds.append(xstd)\n",
    "            else:\n",
    "                xmean = torch.concat([xstmean, xmidmean, xendmean], dim = 1)\n",
    "                xmeans.append(xmean)\n",
    "        if getstd:\n",
    "            return torch.concat(xmeans, dim = 0), torch.concat(xstds, dim = 0)\n",
    "        else:\n",
    "            return torch.concat(xmeans, dim = 0)\n",
    "\n",
    "    def get_mean_std(self, x, windowsize, dim,\n",
    "                     getstd = False, returnzero = False, \n",
    "                     device = \"cpu\"):\n",
    "        if returnzero:\n",
    "            if getstd:\n",
    "                return torch.zeros(1, 0, dim).to(device), torch.zeros(1, 0, dim).to(x.device)\n",
    "            else:\n",
    "                return torch.zeros(1, 0, dim).to(device)\n",
    "        xredmean = reduce(x, \"b (x dx) c -> b x c\", \"mean\",\n",
    "                          dx = windowsize)\n",
    "        if getstd:\n",
    "            xdiff = x - repeat(xredmean, \"b x c -> b (x dx) c\", \n",
    "                          dx = windowsize)\n",
    "            xdiffsq = xdiff * xdiff\n",
    "            xmidstd = torch.sqrt(reduce(xdiffsq, \"b (x dx) c -> b x c\", \"mean\", \n",
    "                                       dx = windowsize))\n",
    "            return xredmean, xmidstd\n",
    "        else:\n",
    "            return xredmean\n",
    "\n",
    "#Simpler reduction using einops expand and reduce to have evenly distributed which also makes easy standard deviation\n",
    "#It also allows smaller than 50 elements to be expanded with the same function - expanding the scope\n",
    "#Not sure if it will be wors or work ok - can see the benefit of keeping a whole number binning like the original\n",
    "#This will be BAD for memory! - but writing it anyway.\n",
    "#Check whether standard deviation is used at all in training - or if it's just an addition for the final so that noise can be added\n",
    "#this noise is for generating diversity\n",
    "\n",
    "class ReductionEven_einops(nn.Module):\n",
    "    def __init__(self, reduce_size=50):\n",
    "        super().__init__()\n",
    "        self.reduce_size = reduce_size\n",
    "\n",
    "    def forward(self, x, getstd=False):\n",
    "        \"\"\"\n",
    "        x: [batch, seq_len, dim]\n",
    "        Returns:\n",
    "            xmean: [batch, reduce_size, dim]\n",
    "            xstd:  [batch, reduce_size, dim] if getstd=True\n",
    "        \"\"\"\n",
    "        batch, seq_len, dim = x.shape\n",
    "\n",
    "        # Step 1: repeat each timestep 50x\n",
    "        x_expanded = repeat(x, \"b s d -> b (s r) d\", r=50)  # [batch, seq_len*50, dim]\n",
    "\n",
    "        # Step 2: reduce into reduce_size chunks\n",
    "        dx = x_expanded.shape[1] // self.reduce_size  # window size for reduction\n",
    "        xmean = reduce(x_expanded, \"b (x dx) d -> b x d\", \"mean\", dx=dx)\n",
    "\n",
    "        if getstd:\n",
    "            # expand mean back to repeated length to compute std\n",
    "            x_diff = x_expanded - repeat(xmean, \"b x d -> b (x dx) d\", dx=dx)\n",
    "            xstd = reduce(x_diff**2, \"b (x dx) d -> b x d\", \"mean\", dx=dx).sqrt()\n",
    "            return xmean, xstd\n",
    "\n",
    "        return xmean\n",
    "\n",
    "# Simpler reduction using nn to have evenly distributed using 'F.adaptive_avg_pool1d'\n",
    "#As before Not sure if it will be worse or work ok - can see the benefit of keeping a whole number binning like the original\n",
    "class ReductionAdaptive(nn.Module):\n",
    "    def __init__(self, reduce_size=50):\n",
    "        super().__init__()\n",
    "        self.reduce_size = reduce_size\n",
    "\n",
    "    def forward(self, x, getstd=False):\n",
    "        \"\"\"\n",
    "        x: [batch, seq_len, dim]\n",
    "        Returns:\n",
    "            xmean: [batch, reduce_size, dim]\n",
    "            xstd:  [batch, reduce_size, dim] if getstd=True\n",
    "        \"\"\"\n",
    "        batch, seq_len, dim = x.shape\n",
    "\n",
    "        # Permute to [batch, dim, seq_len] for adaptive_avg_pool1d\n",
    "        x_perm = x.permute(0, 2, 1)  # [B, D, L]\n",
    "\n",
    "        # Step 1: Adaptive average pooling to fixed length\n",
    "        x_mean = F.adaptive_avg_pool1d(x_perm, output_size=self.reduce_size)\n",
    "        x_mean = x_mean.permute(0, 2, 1)  # [B, reduce_size, D]\n",
    "\n",
    "        if getstd:\n",
    "            # note while this uses more memory - it shouldn't be too bad as we are not actually training here \n",
    "            # in a memory limited setting - we can add a function that uses a for loop instead \n",
    "            #-this will fupport using the model on larger batches\n",
    "            # Step 1: repeat each timestep 50x\n",
    "            x_expanded = repeat(x, \"b s d -> b (s r) d\", r=50)  # [batch, seq_len*50, dim]\n",
    "    \n",
    "            # Step 2: reduce into reduce_size chunks\n",
    "            dx = x_expanded.shape[1] // self.reduce_size  # window size for reduction\n",
    "            mean = reduce(x_expanded, \"b (x dx) d -> b x d\", \"mean\", dx=dx)\n",
    "    \n",
    "            # expand mean back to repeated length to compute std\n",
    "            diff = x_expanded - repeat(mean, \"b x d -> b (x dx) d\", dx=dx)\n",
    "            xstd = reduce(diff**2, \"b (x dx) d -> b x d\", \"mean\", dx=dx).sqrt()\n",
    "        \n",
    "            return x_mean, xstd\n",
    "\n",
    "        return x_mean\n",
    "             \n",
    "\n",
    " #       if getstd:\n",
    "        #this is going back to the \n",
    "            # Step 2: Compute standard deviation per pooled bin\n",
    "            # 1. Compute weights of each input step for each pooled bin\n",
    "            # 2. Expand x_mean back to original length using interpolation\n",
    "            # Approximate by linear upsampling\n",
    " #           x_mean_expanded = F.interpolate(\n",
    " #               x_mean.permute(0, 2, 1), size=seq_len, mode='linear', align_corners=False\n",
    " #           ).permute(0, 2, 1)  # [B, seq_len, D]\n",
    "\n",
    "            # 3. Compute per-bin squared deviations\n",
    " #           x_diff_sq = (x - x_mean_expanded) ** 2\n",
    "\n",
    "            # 4. Reduce to same reduce_size bins\n",
    " #           x_diff_sq_perm = x_diff_sq.permute(0, 2, 1)  # [B, D, L]\n",
    " #           x_std = F.adaptive_avg_pool1d(x_diff_sq_perm, output_size=self.reduce_size).permute(0, 2, 1)\n",
    " #           x_std = torch.sqrt(x_std + 1e-8)  # epsilon for numerical stability\n",
    " #\n",
    " #           return x_mean, x_std\n",
    "\n",
    " #       return x_mean\n",
    "\n",
    "\n",
    "# the original raygun Repetition - consider renaming it expansion for clarity - this is in the decoder part\n",
    "class Repetition(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        self, noise_threshold\n",
    "        \"\"\"\n",
    "        super(Repetition, self).__init__()\n",
    "        return\n",
    "        \n",
    "    def forward(self, encoding, finallengths):\n",
    "        \"\"\"\n",
    "        encoding     => torch.Tensor [batch, REDUCTION_DIM, 1280]; Fixed dimensional representations\n",
    "        finallengths => torch.Tensor [batch]; target lengths for each batch\n",
    "        \"\"\"\n",
    "        batch, encoderlength, dim = encoding.shape\n",
    "\n",
    "        if isinstance(finallengths, int):\n",
    "            assert batch == 1\n",
    "            finallengths = torch.tensor([finallengths], dtype = int)\n",
    "\n",
    "        xs = []\n",
    "        maxlength = torch.max(finallengths)\n",
    "\n",
    "        for i in range(batch):\n",
    "            finallength = finallengths[i]\n",
    "            reps        = finallength // encoderlength\n",
    "            gap         = finallength % encoderlength\n",
    "            gapleft     = gapright = gap // 2\n",
    "\n",
    "            if gap % 2 == 1:\n",
    "                gapleft += 1\n",
    "            \n",
    "            mid = encoderlength - gap\n",
    "            if gapleft == 0:\n",
    "                xstart = torch.zeros(1, 0, dim).to(encoding.device)\n",
    "            else:\n",
    "                encstart = encoding[i, :gapleft, :].unsqueeze(0)\n",
    "                xstart = repeat(encstart, f\"b h c -> b (h rep) c\", rep=reps+1)\n",
    "            encmid = encoding[i, gapleft:gapleft + mid, :].unsqueeze(0)\n",
    "            xmid = repeat(encmid, f\"b h c -> b (h rep) c\", rep = reps)\n",
    "            if gapright == 0:\n",
    "                xend = torch.zeros(1, 0, dim).to(encoding.device)\n",
    "            else:\n",
    "                encend = encoding[i, gapleft + mid:, :].unsqueeze(0)\n",
    "                xend = repeat(encend, f\"b h c -> b (h rep) c\", rep = reps+1)\n",
    "            padding  = torch.zeros(1, maxlength - finallength, dim).to(encoding.device)\n",
    "            xs.append(torch.concat([xstart, xmid, xend, padding], dim = 1))\n",
    "        return torch.concat(xs, dim = 0)\n",
    "\n",
    "#my repetition function - can also reduce the size below 50\n",
    "#possibly very high use of memory (you are expanding by the output length\n",
    "class ExpansionEven_einops(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, finallengths):\n",
    "        \"\"\"\n",
    "        encoding     => torch.Tensor [batch, REDUCTION_DIM, 1280]; Fixed dimensional representations\n",
    "        finallengths => torch.Tensor [batch]; target lengths for each batch\n",
    "        \"\"\"\n",
    "        batch, seq_len, dim = encoding.shape\n",
    "        \n",
    "        for i in range(batch):\n",
    "            finallength = finallengths[i]          \n",
    "\n",
    "        # Step 1: repeat each timestep 50x\n",
    "        x_expanded = repeat(x, \"b s d -> b (s r) d\", r=finallength)  # [batch, seq_len*50, dim]\n",
    "\n",
    "        # Transpose so dim 1 becomes the last dimension\n",
    "        x_expanded_t = x.transpose(1, 2)  # shape (2, 4, 5)\n",
    "\n",
    "        # Interpolate along last dimension (originally dim 1)\n",
    "        x_mean_t = F.interpolate(x_t, size=finallength, mode='linear', align_corners=False)\n",
    "        \n",
    "        # now I need to concatenate them together like in the example be for returning \n",
    "        #- but the shapes need to align - continue to write\n",
    "\n",
    "        return  # add to return the final concatenated bit\n",
    "\n",
    "# Can also do standard linear interpolation or nearest neighbour with smoothing - add below\n",
    "\n",
    "\n",
    "\n",
    "class Reduction_and_Expansion_arearesamp_single(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, finallength):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape [B, L, D]\n",
    "        finallength: int, new length for dimension 1 (L)\n",
    "        Returns: [B, finallength, D]\n",
    "        \"\"\"\n",
    "        B, L, D = x.shape  # [B, L, D]\n",
    "\n",
    "        # Step 1: Transpose to [B, D, L] so L is the last dimension\n",
    "        x = x.transpose(1, 2)  # [B, D, L]\n",
    "\n",
    "        # Step 2: Add channel dim → [B, 1, D, L]\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # Step 3: Interpolate with area mode\n",
    "        x = F.interpolate(x, size=(D, finallength), mode='area')\n",
    "\n",
    "        # Step 4: Remove channel dim → [B, D, finallength]\n",
    "        x = x.squeeze(1)\n",
    "\n",
    "        # Step 5: Transpose back to [B, finallength, D]\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ReductionAndExpansionAreaResamp(nn.Module):\n",
    "    \"\"\"\n",
    "    Resamples sequences with variable input and output lengths using 'area' interpolation.\n",
    "    Supports masking of padded input tokens and variable target lengths per batch.\n",
    "\n",
    "    Args:\n",
    "        None (can later add stdev/noise parameters)\n",
    "\n",
    "    Inputs:\n",
    "        x: Tensor of shape [B, L_max, D]\n",
    "        padding_mask: Bool tensor [B, L_max], where True = padded (invalid)\n",
    "        finallength: int | list[int] | tensor[int]\n",
    "            Target length(s) per batch element.\n",
    "\n",
    "    Outputs:\n",
    "        padded_out: Tensor [B, L_out_max, D] (zero-padded)\n",
    "        out_mask:   Bool tensor [B, L_out_max] (True = padded)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        finallength,\n",
    "        padding_mask: torch.Tensor = None,\n",
    "    ):\n",
    "        B, L_max, D = x.shape\n",
    "\n",
    "        if padding_mask is None:\n",
    "            padding_mask = torch.zeros(B, L_max, dtype=torch.bool, device=x.device)\n",
    "        \n",
    "        assert padding_mask.shape == (B, L_max), \"padding_mask must be [B, L_max]\"\n",
    "\n",
    "        # Normalize finallength → Tensor[B]\n",
    "        if isinstance(finallength, int):\n",
    "            finallengths = torch.full((B,), finallength, dtype=torch.long, device=x.device)\n",
    "        else:\n",
    "            finallengths = torch.as_tensor(finallength, dtype=torch.long, device=x.device)\n",
    "            assert finallengths.shape[0] == B, \"finallength must have one value per batch element\"\n",
    "\n",
    "        # --- Preallocate outputs ---\n",
    "        max_len_out = finallengths.max().item()\n",
    "        padded_out = torch.zeros(B, max_len_out, D, dtype=x.dtype, device=x.device)\n",
    "        out_mask = torch.ones(B, max_len_out, dtype=torch.bool, device=x.device)  # all padded initially\n",
    "\n",
    "        # --- Single pass loop with enumerate ---\n",
    "        for b, target_len in enumerate(finallengths.tolist()):\n",
    "            # Extract valid (unpadded) region\n",
    "            valid_len = (~padding_mask[b]).sum().item()\n",
    "            seq = x[b, :valid_len]  # [L_b, D]\n",
    "\n",
    "            # Interpolate to target length\n",
    "            seq = seq.unsqueeze(0).transpose(1, 2).unsqueeze(1)  # [1, 1, D, L_b]\n",
    "            out = F.interpolate(seq, size=(D, target_len), mode=\"area\")\n",
    "            out = out.squeeze(1).transpose(1, 2)  # [1, target_len, D]\n",
    "\n",
    "            # Place in padded_out and mark valid positions in mask\n",
    "            Lb = out.shape[1]\n",
    "            padded_out[b, :Lb] = out\n",
    "            out_mask[b, :Lb] = False  # False = valid, True = padded\n",
    "\n",
    "        return padded_out, out_mask\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd59b4bf-0291-4a15-af54-6d0d935242bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  1.,  1.],\n",
      "         [ 2.,  2.,  2.],\n",
      "         [ 3.,  3.,  3.],\n",
      "         [ 4.,  4.,  4.],\n",
      "         [ 5.,  5.,  5.],\n",
      "         [ 6.,  6.,  6.],\n",
      "         [ 7.,  7.,  7.],\n",
      "         [ 8.,  8.,  8.],\n",
      "         [ 9.,  9.,  9.],\n",
      "         [10., 10., 10.]]])\n",
      "torch.Size([1, 10, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1.5000, 1.5000, 1.5000],\n",
       "         [2.5000, 2.5000, 2.5000],\n",
       "         [4.0000, 4.0000, 4.0000],\n",
       "         [5.5000, 5.5000, 5.5000],\n",
       "         [7.0000, 7.0000, 7.0000],\n",
       "         [8.5000, 8.5000, 8.5000],\n",
       "         [9.5000, 9.5000, 9.5000]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the below is not ready and does not fit into the model ....\n",
    "\n",
    "class Reduction_and_Expansion_arearesamp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, finallength): #recompute_scale_factor #align corners - I think this has no effect\n",
    "        \"\"\"\n",
    "        x: Tensor of shape [B, L, D]\n",
    "        finallength: int, new length for dimension 1 (L)\n",
    "        Returns: [B, finallength, D]\n",
    "        \"\"\"\n",
    "        B, L, D = x.shape  # [B, L, D]\n",
    "\n",
    "        # Step 1: Transpose to [B, D, L] so L is the last dimension\n",
    "        x = x.transpose(1, 2)  # [B, D, L]\n",
    "\n",
    "        # Step 2: Add channel dim → [B, 1, D, L]\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # Step 3: Interpolate with area mode\n",
    "        x = F.interpolate(x, size=(D, finallength), mode='area')\n",
    "\n",
    "        # Step 4: Remove channel dim → [B, D, finallength]\n",
    "        x = x.squeeze(1)\n",
    "\n",
    "        # Step 5: Transpose back to [B, finallength, D]\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create a 1D tensor [1, 2, 3, 4, 5]\n",
    "vals = torch.arange(1, 11).view(1, 10, 1).float()  # Shape: [1, 5, 1]\n",
    "\n",
    "# Expand to [1, 5, 3]\n",
    "result = vals.expand(1, 10, 3)\n",
    "\n",
    "print(result)\n",
    "print(result.shape)  # torch.Size([1, 5, 3])\n",
    "\n",
    "trial = Reduction_and_Expansion_arearesamp()\n",
    "\n",
    "trial.forward(result,finallength=7)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7835e9f0-1711-4ee1-b4fa-c276d967463c",
   "metadata": {},
   "source": [
    "# The Full Encoder class that uses all the previous classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "616d02c7-9f10-4ea3-a583-663ce8303d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From raygun file (model vs2)\n",
    "class RaygunEncoder(nn.Module):\n",
    "    def __init__(self, dim = 1280, reduction = 50,\n",
    "                 convkernel = 7,\n",
    "                 nhead = 20, numencoders = 2, dropout = 0.2,\n",
    "                 activation = \"gelu\"):\n",
    "        super(RaygunEncoder, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.encoders = nn.ModuleList()\n",
    "        for i in range(numencoders):\n",
    "            self.encoders.append(Block(dim = dim, \n",
    "                                       convkernel = convkernel, \n",
    "                                       attnheads = nhead))\n",
    "\n",
    "\n",
    "        self.redlength = reduction\n",
    "        self.reduction = Reduction(reduce_size = reduction)\n",
    "        self.final     = nn.Sequential(\n",
    "                            nn.Linear(dim * (numencoders+1), dim // (numencoders + 1) * 4),\n",
    "                            nn.SiLU(),\n",
    "                            nn.Linear(dim // (numencoders + 1) * 4, dim)\n",
    "                         )\n",
    "\n",
    "        nn.init.xavier_uniform_(self.final[0].weight, gain=1e-3)\n",
    "        nn.init.xavier_uniform_(self.final[2].weight, gain=1e-3)\n",
    "        nn.init.constant_(self.final[0].bias, 0)\n",
    "        nn.init.constant_(self.final[2].bias, 0)\n",
    "\n",
    "    def reduce(self, x, mask = None, noise = None):\n",
    "        \"\"\"\n",
    "        Use the Reduction operation to compress the PLM representation to a fixed-dimension space.\n",
    "        \"\"\"\n",
    "        batch, _, _ = x.shape\n",
    "        if noise is not None:\n",
    "            redmean, redstd = self.reduction(x, mask = mask, getstd = True)\n",
    "            reduced = redmean + torch.randn_like(redstd, device = x.device) * redstd * noise\n",
    "        else:\n",
    "            reduced = self.reduction(x, mask = mask, getstd = False)\n",
    "        return reduced\n",
    "\n",
    "    def forward(self, x, mask = None, noise = None):\n",
    "        \"\"\"\n",
    "        If error_c is provided, noise component is incorporated into the \n",
    "        fixed-dimensional representation. \n",
    "        \"\"\"\n",
    "        enc = self.reduce(x, mask = mask, noise = noise)\n",
    "        residues = [enc]\n",
    "        for mod in self.encoders:\n",
    "            xresidue = mod(x, mask = mask)\n",
    "            residue  = mod(self.reduce(xresidue, mask = mask, noise = noise)) # \n",
    "            x        = x + xresidue\n",
    "            residues.append(residue)\n",
    "\n",
    "        finalresidue = self.final(torch.concat(residues, dim = -1)) \n",
    "        return enc + finalresidue      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a97c0e-2a32-483c-ada4-2890b9f9e139",
   "metadata": {},
   "source": [
    "# Decoder Block\n",
    "\n",
    "# Let's do the Same with the decoder block\n",
    "\n",
    "(Less detail though as now we understand roughly what is going on\n",
    "\n",
    "The decoder If you look at the model is very similar to the encoder but with repetition to expand back to a larger space\n",
    "```\n",
    "(decoder): RaygunDecoder(\n",
    "    (dbefore): ModuleList(\n",
    "      (0-11): 12 x Block(\n",
    "        (encoder): TransformerLayer(\n",
    "          (self_attn): MultiheadAttention(\n",
    "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "            (rot_emb): RotaryEmbedding()\n",
    "          )\n",
    "          (self_attn_layer_norm): ESM1LayerNorm()\n",
    "          (fc1): Linear(in_features=1280, out_features=2560, bias=True)\n",
    "          (fc2): Linear(in_features=2560, out_features=1280, bias=True)\n",
    "          (final_layer_norm): ESM1LayerNorm()\n",
    "        )\n",
    "        (convblock): ConvBlock(\n",
    "          (c1): ConvMasked(\n",
    "            (conv): Conv1d(1280, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
    "          )\n",
    "          (s1): SiLU()\n",
    "          (c2): ConvMasked(\n",
    "            (conv): Conv1d(640, 320, kernel_size=(3,), stride=(1,), padding=valid)\n",
    "          )\n",
    "          (s2): SiLU()\n",
    "          (c3): ConvMasked(\n",
    "            (conv): Conv1d(320, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
    "          )\n",
    "          (s3): SiLU()\n",
    "        )\n",
    "        (final): Linear(in_features=640, out_features=1280, bias=True)\n",
    "      )\n",
    "    )\n",
    "    (repetition): Repetition()\n",
    "    (dafter): ModuleList(\n",
    "      (0-12): 13 x Block(\n",
    "        (encoder): TransformerLayer(\n",
    "          (self_attn): MultiheadAttention(\n",
    "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "            (rot_emb): RotaryEmbedding()\n",
    "          )\n",
    "          (self_attn_layer_norm): ESM1LayerNorm()\n",
    "          (fc1): Linear(in_features=1280, out_features=2560, bias=True)\n",
    "          (fc2): Linear(in_features=2560, out_features=1280, bias=True)\n",
    "          (final_layer_norm): ESM1LayerNorm()\n",
    "        )\n",
    "        (convblock): ConvBlock(\n",
    "          (c1): ConvMasked(\n",
    "            (conv): Conv1d(1280, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
    "          )\n",
    "          (s1): SiLU()\n",
    "          (c2): ConvMasked(\n",
    "            (conv): Conv1d(640, 320, kernel_size=(3,), stride=(1,), padding=valid)\n",
    "          )\n",
    "          (s2): SiLU()\n",
    "          (c3): ConvMasked(\n",
    "            (conv): Conv1d(320, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
    "          )\n",
    "          (s3): SiLU()\n",
    "        )\n",
    "        (final): Linear(in_features=640, out_features=1280, bias=True)\n",
    "      )\n",
    "    )\n",
    "    (final): Sequential(\n",
    "      (0): Linear(in_features=17920, out_features=364, bias=True)\n",
    "      (1): SiLU()\n",
    "      (2): Linear(in_features=364, out_features=1280, bias=True)\n",
    "    )\n",
    "  )\n",
    "  (esmdecoder): DecoderBlock(\n",
    "    (encoder): TransformerLayer(\n",
    "      (self_attn): MultiheadAttention(\n",
    "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
    "        (rot_emb): RotaryEmbedding()\n",
    "      )\n",
    "      (self_attn_layer_norm): ESM1LayerNorm()\n",
    "      (fc1): Linear(in_features=1280, out_features=2560, bias=True)\n",
    "      (fc2): Linear(in_features=2560, out_features=1280, bias=True)\n",
    "      (final_layer_norm): ESM1LayerNorm()\n",
    "    )\n",
    "    (final): Sequential(\n",
    "      (0): Linear(in_features=1280, out_features=320, bias=True)\n",
    "      (1): Dropout(p=0.2, inplace=False)\n",
    "      (2): Linear(in_features=320, out_features=32, bias=True)\n",
    "    )\n",
    "  )\n",
    ")\n",
    "\n",
    "```\n",
    "Verify:\n",
    "You do 13 of the block layer architecture, which does attention and convolutions.\n",
    "\n",
    "You concatenate together\n",
    "\n",
    "You do Repetition to Expand - Again I will not go into detail into this \n",
    "\n",
    "Then you do 13 more of the block architecture\n",
    "\n",
    "\n",
    "\n",
    "Then you do Final to put into the right embedding space and use the EsmDecoder (DecoderBlock) to turn back into sequence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cc66d38-2cc7-4ad8-b97d-802882ecb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaygunDecoder(nn.Module):\n",
    "    def __init__(self, dim = 1280, numdecoders = 5, convkernel = 7,\n",
    "                 nhead = 20, dropout = 0.1, activation = \"gelu\"):\n",
    "        super(RaygunDecoder, self).__init__()\n",
    "        self.dbefore = nn.ModuleList()\n",
    "         \n",
    "        for i in range(numdecoders):\n",
    "            self.dbefore.append(Block(dim = dim,\n",
    "                                      convkernel = convkernel,\n",
    "                                      attnheads = nhead,\n",
    "                                      ))\n",
    "\n",
    "        self.repetition = Repetition()\n",
    "\n",
    "        self.dafter = nn.ModuleList()\n",
    "        for i in range(numdecoders+1):\n",
    "            self.dafter.append(Block(dim = dim,\n",
    "                                      convkernel = convkernel, \n",
    "                                      attnheads = nhead, \n",
    "                                      ))\n",
    "        self.final = nn.Sequential(\n",
    "                            nn.Linear(dim * (numdecoders+2), dim // (numdecoders+2) * 4),\n",
    "                            nn.SiLU(),\n",
    "                            nn.Linear(dim // (numdecoders+2) * 4, dim)\n",
    "                        )\n",
    "\n",
    "    def forward(self, encoding, finallengths, mask = None):\n",
    "        \"\"\"\n",
    "        Decoder is entirely deterministic. No noise added here.\n",
    "        \"\"\"\n",
    "        out = self.repetition(encoding, finallengths)\n",
    "        # construct different encoding replicates\n",
    "        ereplicates = []\n",
    "        ereplicates.append(encoding)\n",
    "        for mod in self.dbefore:\n",
    "            encoding = encoding + mod(encoding, mask = mask)\n",
    "            ereplicates.append(encoding)\n",
    "        ## for each replicates, expand and apply model\n",
    "        outreplicates = [out]\n",
    "        for ereplicate, mod in zip(ereplicates, self.dafter):\n",
    "            outreplicates.append(mod(self.repetition(ereplicate, finallengths),\n",
    "                                    mask = mask))\n",
    "        return out + self.final(torch.concat(outreplicates, dim = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8923f5c7-e961-4832-ab9e-dc974dcacaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from esmdecoder file: \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, dim = 1280, nhead = 20, dropout = 0.2, fixed_batching=False):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.encoder = TransformerLayer(embed_dim = dim, \n",
    "                                       ffn_embed_dim = 2 * dim,\n",
    "                                       attention_heads = nhead,\n",
    "                                        use_rotary_embeddings = True\n",
    "                                       )\n",
    "        self.final = nn.Sequential(nn.Linear(dim, dim // 4),\n",
    "                                  nn.Dropout(p=dropout),\n",
    "                                  nn.Linear(dim // 4, 32))\n",
    "        self.fixed_batching=fixed_batching\n",
    "        return\n",
    "    \n",
    "    def load_pretrained(self, filename):\n",
    "        checkpoint = torch.load(filename)[\"model_state_dict\"]\n",
    "        self.load_state_dict(checkpoint)\n",
    "        del checkpoint\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.fixed_batching:\n",
    "            x = rearrange(x, \"b n c -> n b c\")\n",
    "        x, _ = self.encoder(x)\n",
    "        if self.fixed_batching:\n",
    "            x = rearrange(x, \"n b c -> b n c\")\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69d839a-f10f-48a6-a1fb-372b4ee91d1e",
   "metadata": {},
   "source": [
    "# The Whole encoder-decoder together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be1b8ac7-9956-4abd-bfa2-4da121fefffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Raygun(nn.Module):\n",
    "    def __init__(self, dim = 1280, nhead = 20, convkernel = 7, \n",
    "                 numencoders = 10, numdecoders = 10,\n",
    "                 dropout = 0.1,\n",
    "                 reduction = 50, activation = \"gelu\",\n",
    "                 esmdecodertotokenfile = None, \n",
    "                 fixed_esm_batching=False):\n",
    "        super(Raygun, self).__init__()\n",
    "        self.encoder = RaygunEncoder(dim     = dim, \n",
    "                                reduction    = reduction, \n",
    "                                convkernel   = convkernel,\n",
    "                                numencoders  = numencoders, \n",
    "                                dropout      = dropout, \n",
    "                                activation   = activation,\n",
    "                                nhead        = nhead)\n",
    "        self.decoder = RaygunDecoder(dim     = dim, \n",
    "                                 nhead       = nhead, \n",
    "                                 convkernel  = convkernel,\n",
    "                                 numdecoders = numdecoders,\n",
    "                                 dropout     = dropout, \n",
    "                                 activation  = activation)\n",
    "\n",
    "        self.esmdecoder = DecoderBlock(dim = dim, \n",
    "                                      nhead = 20, \n",
    "                                      fixed_batching=fixed_esm_batching)\n",
    "        if esmdecodertotokenfile is not None:\n",
    "            checkpoint = torch.load(esmdecodertotokenfile)\n",
    "            self.esmdecoder.load_state_dict(checkpoint[\"model_state\"])\n",
    "            del checkpoint\n",
    "        self.alphtotoks  = {'<cls>': 0, '<pad>': 1, '<eos>': 2, '<unk>': 3, 'L': 4, 'A': 5, 'G': 6, 'V': 7, 'S': 8, 'E': 9, 'R': 10, 'T': 11, 'I': 12, 'D': 13, 'P': 14, 'K': 15, 'Q': 16, 'N': 17, 'F': 18, 'Y': 19, 'M': 20, 'H': 21, 'W': 22, 'C': 23, 'X': 24, 'B': 25, 'U': 26, 'Z': 27, 'O': 28, '.': 29, '-': 30, '<null_1>': 31, '<mask>': 32}\n",
    "        self.esmalphdict = {i:k for k, i in self.alphtotoks.items()}\n",
    "\n",
    "    def get_sequence_from_logits(self, logits, lengths):\n",
    "        batch, seq, _ = logits.shape\n",
    "        if batch == 1:\n",
    "            assert isinstance(lengths, int) or lengths.shape[0] == 1, \"batch=1 but multiple lengths provided\"\n",
    "            if isinstance(lengths, int):\n",
    "                lengths = [lengths]\n",
    "        else:\n",
    "            assert len(lengths.shape) == 1 and lengths.shape[0] == batch, \"batch size and `lengths` dimension should be the same\"\n",
    "        output_seqs   = []\n",
    "        with torch.no_grad():\n",
    "            for idx, length in enumerate(lengths):\n",
    "                logit   = logits[idx, :length, :]\n",
    "                ptokens = torch.argmax(logit, dim = -1).cpu().numpy().tolist()\n",
    "                pseqs   = \"\".join([self.esmalphdict[t] if t in set(range(4, 29)) else \"X\" \n",
    "                                  for t in ptokens])\n",
    "                output_seqs.append(pseqs)\n",
    "        return output_seqs\n",
    "\n",
    "    def get_sequences_from_fixed(self, fixedembs, lengths):\n",
    "        with torch.no_grad():\n",
    "            out    = self.decoder(fixedembs, lengths)\n",
    "            logits = self.esmdecoder(out)\n",
    "        return self.get_sequence_from_logits(logits, lengths)\n",
    "    \n",
    "    def forward(self, x, mask = None, \n",
    "                target_lengths = None, \n",
    "                noise = None, \n",
    "                token = None, \n",
    "                return_logits_and_seqs = False):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        x    -> [batch, seq, dim]: ESM-2 650M embedding\n",
    "        mask -> [batch, seq]: Binary matrix. Suppose the sequence length of a  `batch_id` is `n`. Then mask[batch_id] should be such that mask[batch_id, :n] = 1 and mask[batch_id, n:] = 0  \n",
    "        output_lengths -> [batch]: target length\n",
    "        \"\"\"\n",
    "        batch, length_, dim = x.shape\n",
    "        if target_lengths is not None:\n",
    "            assert target_lengths.shape[0] == batch, \"`output_lengths` should be a 1d tensor, its dimension should match the batch size\"\n",
    "            lengths = target_lengths\n",
    "        elif batch == 1:\n",
    "            lengths = length_  \n",
    "        else:\n",
    "            assert mask is not None, \"batch larger than 1 but mask is Null\"\n",
    "            lengths = mask.sum(dim = -1)\n",
    "        mem = self.encoder(x, mask = mask, noise = noise)\n",
    "        out = self.decoder(mem, lengths)\n",
    "        \n",
    "        result = {\"fixed_length_embedding\": mem, \n",
    "                 \"reconstructed_embedding\": out}\n",
    "        \n",
    "        if token is not None or return_logits_and_seqs:\n",
    "            logits          = self.esmdecoder(out) #batch, seq, token\n",
    "            result[\"logits\"] = logits\n",
    "            \n",
    "        if token is not None:\n",
    "            if len(token.shape) == 3:\n",
    "                tok   = rearrange(token, \"b h k -> (b h k)\")\n",
    "            else:\n",
    "                tok   = rearrange(token, \"b k -> (b k)\")\n",
    "            loss      = F.cross_entropy(rearrange(logits, \"b h k -> (b h) k\"), \n",
    "                                        tok, ignore_index = 1)\n",
    "            result[\"ce_loss\"] = loss\n",
    "        if return_logits_and_seqs:\n",
    "            result[\"generated-sequences\"] = self.get_sequence_from_logits(logits, lengths)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37180a4d-78c7-4dc2-b817-6391fe3a72db",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c265e562-f91b-443f-8eb0-5bc42e5bd0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaygunData(Dataset):\n",
    "    def __init__(self, fastafile, alphabet, model = None,\n",
    "                 precomputed = False, save = False,\n",
    "                 embeddingfolder = None, \n",
    "                 device = \"cpu\", no_records = -1,\n",
    "                 maxlength=1000, minlength=50):\n",
    "        \"\"\"\n",
    "        parameters:\n",
    "        model, alphabet => ESM-2 650M model and alphabet; ensure that it is in eval mode\n",
    "        precomputed     => to indicate that the embeddings are precomputed\n",
    "        save            => to save the computed embeddings\n",
    "        embeddingfolder => if precomputed is True, it is the location where the embeddings are stored\n",
    "                           if save is True, it is the location where the embeddings are saved\n",
    "        no_records      => if positive, the number of items in the __getitem__ is overriden to the \n",
    "                           specified value\n",
    "        maxlength       => maximum sequence length to allow\n",
    "        \"\"\"\n",
    "        assert precomputed == False or embeddingfolder is not None, \"precomputed is True but the `embeddingfolder` is not provided\"\n",
    "        assert save == False or embeddingfolder is not None, \"save is True but the save location,  denoted by `embeddingfolder` is None\"\n",
    "        assert precomputed == True or model is not None, \"precomputed is False, but the esm model is not provided\"\n",
    "        assert alphabet is not None, \"ESM alphabet is not provided\"\n",
    "        ## NOTE: ESM-2 device location and `device` should be the same\n",
    "        self.device          = device\n",
    "\n",
    "        self.fastafile = fastafile\n",
    "        self.model     = model\n",
    "        self.alphabet  = alphabet\n",
    "        self.bc        = self.alphabet.get_batch_converter()\n",
    "        self.records   = list(SeqIO.parse(fastafile, \"fasta\"))\n",
    "        self.sequences = [(rec.id, str(rec.seq)) for rec in self.records if \n",
    "                         len(rec.seq) <= maxlength and len(rec.seq) >= minlength]\n",
    "        if precomputed:\n",
    "            h5exists = lambda x : os.path.exists(f\"{embeddingfolder}/{x}.h5\")\n",
    "            self.sequences = [s for s in self.sequences if h5exists(s[0])]\n",
    "            self.save      = False            # no need to save if precomputed\n",
    "        else:\n",
    "            self.save      = save\n",
    "        if no_records < 0:\n",
    "            no_records = len(self.sequences)\n",
    "\n",
    "        self.no_records      = no_records\n",
    "        self.embeddingfolder = embeddingfolder\n",
    "        self.precomputed     = precomputed\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.no_records\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx]\n",
    "    \n",
    "    def collatefn(self, batches):\n",
    "        ids, seqs  = zip(*batches)\n",
    "        lengths    = [len(seq) for seq in seqs]\n",
    "        maxlen     = max(lengths)\n",
    "        nbatch     = len(lengths)\n",
    "        mask       = torch.arange(maxlen, dtype = int).unsqueeze(0).expand(nbatch, maxlen) < torch.tensor(lengths, dtype = int).unsqueeze(1)\n",
    "        embeddings = []\n",
    "        # TOFIX: sometimes batch_converter adds padding token in the middle of the sequence\n",
    "        tokens = []\n",
    "        for b in batches:\n",
    "            _, _, toks = self.bc([b]) # [1, seqlen]\n",
    "            tokens.append(toks.squeeze(0))\n",
    "        tokens       = pad_sequence(tokens, padding_value = 1)\n",
    "        tokens       = rearrange(tokens, \"s b -> b s\")\n",
    "\n",
    "        tokens       = tokens.to(self.device)\n",
    "        if self.precomputed:\n",
    "            for idx in ids:\n",
    "                efile  = f\"{self.embeddingfolder}/{idx}.h5\"\n",
    "                with h5py.File(efile, \"r\") as hf:\n",
    "                    emb  = hf.get(idx)[:]\n",
    "                    embeddings.append(torch.from_numpy(hf.get(idx)[:]).to(self.device))\n",
    "            embeddings = pad_sequence(embeddings)\n",
    "            embeddings = rearrange(embeddings, \"n b c -> b n c\")\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                embeddings = self.model(tokens, repr_layers = [33], \n",
    "                                        return_contacts = False)[\"representations\"][33]\n",
    "                embeddings = embeddings[:, 1:-1, :] # remove the start token\n",
    "        if self.save:\n",
    "            for i, idx, in enumerate(ids):\n",
    "                efile = f\"{self.embeddingfolder}/{idx}.h5\"\n",
    "                with h5py.File(efile, \"w\") as hf:\n",
    "                    hf.create_dataset(idx, data = embeddings[0, :lengths[i], :].cpu().numpy())\n",
    "        # remove start and end tokens\n",
    "        tokens = tokens[:, 1:]\n",
    "        tokens[tokens == 2] = 1 # 2 denotes eos\n",
    "\n",
    "        return tokens[:, :-1].cpu(), embeddings.cpu(), mask, batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c03b9c6-f632-4ac8-b341-f5a9c6032c9b",
   "metadata": {},
   "source": [
    "# Lightning wrapper for Training\n",
    "\n",
    "The lightning wrapper manages the training\n",
    "\n",
    "It is fairly self explanatory. It sits on top of the pytorch and deals with splitting batches over GPUs and means you do not have to call forward or backward manually at all. ALso It can include logging etc.\n",
    "\n",
    "See the documentation: \n",
    "\n",
    "https://lightning.ai/docs/pytorch/LTS/common/lightning_module.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92bb72a3-2a5b-40c4-8117-e5b26712ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINALLOWEDLENGTH = 50\n",
    "\n",
    "class RaygunLightning(L.LightningModule):\n",
    "    def __init__(self, raygun, lr = 1e-3, \n",
    "                crossentropyloss = 1., \n",
    "                reconstructionloss = 1., \n",
    "                replicateloss = 1.,\n",
    "                log_wandb = False,\n",
    "                traininglog = \"traininglog.txt\",\n",
    "                finetune = False):\n",
    "        super().__init__()\n",
    "        self.model  = raygun\n",
    "        self.lr     = lr\n",
    "        self.crossentropyloss = crossentropyloss\n",
    "        self.reconstructloss  = reconstructionloss\n",
    "        self.replicateloss    = replicateloss\n",
    "        self.trainlosses      = defaultdict(list)\n",
    "        self.vallosses        = defaultdict(list)\n",
    "        self.epoch            = 0\n",
    "        bl                    = substitution_matrices.load(\"BLOSUM62\")\n",
    "        self.blosummat        = pd.DataFrame(bl, columns = list(bl.alphabet))\n",
    "        self.blosummat.index  = list(bl.alphabet)\n",
    "        self.decodermodel     = raygun.esmdecoder\n",
    "        \n",
    "        self.esmalphabet      = {'<cls>': 0, '<pad>': 1, '<eos>': 2, '<unk>': 3, 'L': 4, 'A': 5, 'G': 6, 'V': 7, \n",
    "                                 'S': 8, 'E': 9, 'R': 10, 'T': 11, 'I': 12, 'D': 13, 'P': 14, 'K': 15, 'Q': 16, \n",
    "                                 'N': 17, 'F': 18, 'Y': 19, 'M': 20, 'H': 21, 'W': 22, 'C': 23, 'X': 24, 'B': 25, \n",
    "                                 'U': 26, 'Z': 27, 'O': 28, '.': 29, '-': 30, '<null_1>': 31, '<mask>': 32}\n",
    "        self.toktoalphdict    = {k: i for i, k in self.esmalphabet.items()} \n",
    "        \n",
    "        self.log_wandb        = log_wandb\n",
    "        self.traininglog      = traininglog\n",
    "        \n",
    "        # loss regularization\n",
    "        self.runid            = 0\n",
    "        self.tlosshistory     = []\n",
    "        self.coolingtime      = 100\n",
    "        self.averagingwindow  = 500\n",
    "        self.std_threshold    = 15\n",
    "        self.finetune         = finetune\n",
    "\n",
    "    def log_error(self, batch, loss):\n",
    "        idx, seq       = zip(*batch)\n",
    "        df             = pd.DataFrame({\"id\" : idx, \n",
    "                                       \"seq\" : seq})\n",
    "        running_avg    = np.mean(self.tlosshistory)\n",
    "        running_std    = np.std(self.tlosshistory)\n",
    "        with open(self.traininglog, \"a\") as logf:\n",
    "            logf.write(f\"\\n\\nEpoch {self.epoch}, run {self.runid}\")\n",
    "            logf.write(f\"\\n\\tBatch Loss   : {loss}\\n\")\n",
    "            logf.write(f\"\\n\\tRunning Loss : {running_avg}\" \n",
    "                       + u\" \\u00B1 \" \n",
    "                       + f\"{running_std}\\n\")\n",
    "            logf.write(df.to_string())\n",
    "            \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if not self.finetune:\n",
    "            optimizer = torch.optim.Adam(self.model.parameters(), lr = self.lr)\n",
    "        else:\n",
    "            optimizer = torch.optim.Adam(self.model.decoder.parameters(), lr = self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "        # Return optimizer and scheduler\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\" : {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"Blosum ratio\",\n",
    "                \"interval\" : \"epoch\",\n",
    "                \"freq\"     : 1\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        token, embedding and mask should not contain the begin and end tokens\n",
    "        \"\"\"\n",
    "        tokens, e, mask, binfo = batch\n",
    "        bshape, seq_, _        = e.shape\n",
    "        if mask is None:\n",
    "            assert bshape == 1, \"Batch is larger than 1 but no mask provided\"\n",
    "            ## required when replicateloss > 0\n",
    "            newlengths = torch.randint(MINALLOWEDLENGTH, seq_, [1])\n",
    "        else:\n",
    "            lengths    = mask.sum(dim = 1)\n",
    "            newlengths = torch.concat([torch.randint(MINALLOWEDLENGTH, l, [1]) \n",
    "                         for l in lengths]) \n",
    "        tloss = 0\n",
    "        if self.crossentropyloss > 0:\n",
    "            payload    = self.model(e, mask = mask, token = tokens)\n",
    "            result     = payload[\"reconstructed_embedding\"]\n",
    "            mem        = payload[\"fixed_length_embedding\"]\n",
    "            crossloss  = payload[\"ce_loss\"]\n",
    "            tloss      = tloss + self.crossentropyloss * crossloss\n",
    "            self.trainlosses[\"Cross-Entropy Loss\"].append(crossloss.item())\n",
    "            self.log(\"Cross-Entropy Loss\", crossloss.item() if crossloss.item() < 10 else 10)\n",
    "        else:\n",
    "            payload    = self.model(e, mask = mask)\n",
    "            result     = payload[\"reconstructed_embedding\"]\n",
    "            mem        = payload[\"fixed_length_embedding\"]\n",
    "            \n",
    "        if self.reconstructloss > 0:\n",
    "            recloss    = F.mse_loss(result * mask.unsqueeze(-1), e * mask.unsqueeze(-1))\n",
    "            tloss      = tloss + self.reconstructloss * recloss\n",
    "            self.trainlosses[\"Reconstruction Loss\"].append(recloss.item())\n",
    "            self.log(\"Reconstruction Loss\", recloss.item() if recloss.item() < 10 else 10)\n",
    "        if self.replicateloss > 0:\n",
    "            decodedemb = self.model.decoder(mem, newlengths)\n",
    "            reploss    = F.mse_loss(mem, self.model.encoder(decodedemb)) \n",
    "            tloss      = tloss + self.replicateloss * reploss \n",
    "            self.trainlosses[\"Replicate Loss\"].append(reploss.item())\n",
    "            self.log(\"Replicate Loss\", reploss.item() if reploss.item() < 10 else 10)\n",
    "        blosumv, blosumr = self.get_blosum_score(result.detach(), tokens.detach())\n",
    "        self.log(\"Blosum score\", blosumv)\n",
    "        self.log(\"Blosum ratio\", blosumr)\n",
    "        \n",
    "        self.tlosshistory = self.tlosshistory[-self.averagingwindow:]\n",
    "        \n",
    "        self.runid       += 1\n",
    "        if self.runid < self.coolingtime:\n",
    "            self.tlosshistory.append(tloss.item())\n",
    "            return tloss\n",
    "        \n",
    "        running_avg = np.mean(self.tlosshistory)\n",
    "        running_std = np.std(self.tlosshistory)\n",
    "        \n",
    "        if tloss.item() >= running_avg + self.std_threshold * running_std:\n",
    "            self.log_error(binfo, tloss.item())\n",
    "            tloss_ = float(tloss.item()) * 0.01\n",
    "            return tloss / tloss_ * running_avg ## this would ignore the batch\n",
    "        else:\n",
    "            self.tlosshistory.append(tloss.item())\n",
    "            return tloss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        logf = f\"Completed Training Epoch {self.epoch+1}: \"\n",
    "        for k, v in self.trainlosses.items():\n",
    "            logf += f\"{k} : {np.mean(v):.4f}\"\n",
    "        logging.info(logf)\n",
    "        self.trainlosses = defaultdict(list)\n",
    "        self.epoch      += 1\n",
    "        return\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        tokens, e, mask, _ = batch\n",
    "        payload            = self.model(e, mask = mask)\n",
    "        result             = payload[\"reconstructed_embedding\"]\n",
    "        mem                = payload[\"fixed_length_embedding\"]\n",
    "        blosum_curr, blosum_curr_ratio = self.get_blosum_score(result,\n",
    "                                                                tokens)\n",
    "        self.log(\"val_blosum_score\", blosum_curr)\n",
    "        self.log(\"val_blosum_ratio\", blosum_curr_ratio)\n",
    "        self.vallosses[\"Blosum Score\"].append(blosum_curr)\n",
    "        self.vallosses[\"Blosum ratio\"].append(blosum_curr_ratio)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        logf = f\"Completed Validation Epoch {self.epoch}\"\n",
    "        for k, v in self.vallosses.items():\n",
    "            logf += f\"{k} : {np.mean(v): .4f}\"\n",
    "        self.validlosses = defaultdict(list)\n",
    "        return\n",
    "\n",
    "    ### Blosum scores prediction \n",
    "    def convert_tokens_to_alph(self, token, lengths):\n",
    "        \"\"\"\n",
    "        token: tensor [batch, seqlen]\n",
    "        \"\"\"\n",
    "        assert len(token.shape) == 2\n",
    "        batch, _ = token.shape\n",
    "        alphabets = []\n",
    "        for i in range(batch):\n",
    "            li  = lengths[i]\n",
    "            tok = token[i][:li].tolist() \n",
    "            alphabets.append([self.toktoalphdict[t] for t in tok])\n",
    "        return alphabets\n",
    "    \n",
    "    def return_sequences_from_embs(self, embeddings, lengths = None):\n",
    "        \"\"\"\n",
    "        embedding = [batch, seq, dim]\n",
    "        \"\"\"\n",
    "        if len(embeddings.shape) == 2:\n",
    "            embeddings = embeddings.unsqueeze(0)\n",
    "        b, n, d = embeddings.shape\n",
    "        if b != 1:\n",
    "            assert lengths is not None and len(lengths) == b, \\\n",
    "            \"for larger batches, you need to specify the lengths. Additionally, the #lengths should equal the batch size\"\n",
    "        else:\n",
    "            lengths = [n]\n",
    "        pred_alphs = []\n",
    "        for i in range(b):\n",
    "            logits = self.model.esmdecoder(embeddings[i][None, :lengths[i], :])\n",
    "            pred_token = torch.argmax(logits, dim = -1).cpu().numpy()\n",
    "            pred_alph  = self.convert_tokens_to_alph(pred_token, [lengths[i]])\n",
    "            pred_alph  = \"\".join(pred_alph[0])\n",
    "            if b == 1:\n",
    "                return pred_alph\n",
    "            else:\n",
    "                pred_alphs.append(pred_alph)\n",
    "        return pred_alphs\n",
    "        \n",
    "    def get_blosum_score(self, embedding, true_token):\n",
    "        \"\"\"\n",
    "        embedding: tensor [batch, seqlen, dim]\n",
    "        true_token: tensor [batch, seqlen]\n",
    "        \"\"\"\n",
    "        ## logging.info(f\"Tokens shape {true_token.shape}, embed shape {embedding.shape}\")\n",
    "        batch, _, _ = embedding.shape\n",
    "        lengths     = []\n",
    "        \n",
    "        for i in range(batch):\n",
    "            tok  = true_token[i]\n",
    "            lengths.append(tok[tok != 1].shape[0]) # tok being 1 implies padding\n",
    "        with torch.no_grad():\n",
    "            true_alph    = self.convert_tokens_to_alph(true_token.cpu().numpy(),\n",
    "                                                       lengths)\n",
    "            logits       = self.model.esmdecoder(embedding)\n",
    "            pred_tokens  = torch.argmax(logits, dim = -1).cpu().numpy()\n",
    "            pred_alph    = self.convert_tokens_to_alph(pred_tokens, lengths)\n",
    "            blcs, blrs   = [], []\n",
    "            for b in range(batch):\n",
    "                blc, blr       = self.compute_blosum_score(true_alph[b], \n",
    "                                                           pred_alph[b])\n",
    "                blcs.append(blc)\n",
    "                blrs.append(blr)\n",
    "        return np.average(blcs), np.average(blrs)\n",
    "\n",
    "    def compute_blosum_score(self, true, predicted):\n",
    "        blosum_max  = 0\n",
    "        blosum_curr = 0\n",
    "        for p, q in zip(true, predicted):\n",
    "            try:\n",
    "                blosum_c_score = self.blosummat.loc[p.upper(), \n",
    "                                                    q.upper()] # if no p and q, this triggers exception\n",
    "                blosum_max += self.blosummat.loc[p.upper(), \n",
    "                                                 p.upper()]\n",
    "                blosum_curr += blosum_c_score\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        return blosum_curr, blosum_curr / blosum_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f1bf1d-e87a-48cd-923e-59943dcee1d1",
   "metadata": {},
   "source": [
    "# Actual train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55f76f87-a7b6-447f-9a7e-2490d38d363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize, compose\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "console_handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(formatter)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "#@hydra.main(config_path=\"configs/\", config_name=\"train\", version_base = None) #not to use as notebook\n",
    "def main(config: DictConfig):\n",
    "    logger.info(\"Running Raygun training...\")\n",
    "    config = OmegaConf.to_container(config, resolve=True)\n",
    "\n",
    "    # create model and embedding folders\n",
    "    os.makedirs(config[\"model_saveloc\"], exist_ok = True)\n",
    "    if config[\"esm2_embedding_saveloc\"] is not None:\n",
    "        os.makedirs(config[\"model_saveloc\"], exist_ok = True)\n",
    "\n",
    "    # Use ESM-2 650M\n",
    "    esmmodel, esmalphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "    esmmodel              = esmmodel.to(0)\n",
    "    esmmodel.eval()\n",
    "\n",
    "    if config[\"log_wandb\"]:\n",
    "        wandb_logger = WandbLogger(project = \"BATCH-TRAINING-RAYGUN\")\n",
    "    else:\n",
    "        wandb_logger = None\n",
    "\n",
    "    #logger.info(f\"Using pre-trained checkpoint.\")\n",
    "    # load the model \n",
    "    #rayltmodule             = raygun_4_4mil_800M(return_lightning_module=True)\n",
    "    \n",
    "    if \"checkpoint\" in config and config[\"checkpoint\"] is not None:\n",
    "        ckptpath   = Path(config[\"checkpoint\"])\n",
    "        checkpoint = torch.load(ckptpath, weights_only = True)\n",
    "        rayltmodule.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "    rayltmodule.traininglog = config[\"model_saveloc\"] + \"/error-log.txt\"\n",
    "    rayltmodule.log_wandb   = config[\"log_wandb\"]\n",
    "    rayltmodule.lr          = config[\"lr\"]\n",
    "    rayltmodule.finetune    = False\n",
    "    rayltmodule.epoch       = 0\n",
    "    \n",
    "    ## fixed the batching problem \n",
    "    if \"fix_batching_esmdecoder\" in config and config[\"fix_batching_esmdecoder\"]:\n",
    "        rayltmodule.model.esmdecoder.fixed_batching=True\n",
    "    else:\n",
    "        rayltmodule.model.esmdecoder.fixed_batching=False\n",
    "        \n",
    "    \n",
    "    ## train and validation loaders\n",
    "    traindata = RaygunData(fastafile = config[\"trainfasta\"],\n",
    "                           alphabet  = esmalphabet,\n",
    "                           model     = esmmodel, \n",
    "                           device    = 0)\n",
    "    trainloader = DataLoader(traindata, \n",
    "                             shuffle = True, \n",
    "                             batch_size = config[\"batch_size\"],\n",
    "                             collate_fn = traindata.collatefn)\n",
    "    validdata = RaygunData(fastafile = config[\"validfasta\"],\n",
    "                           alphabet  = esmalphabet,\n",
    "                           model     = esmmodel,\n",
    "                           device    = 0)\n",
    "    validloader = DataLoader(validdata, \n",
    "                            shuffle = False,\n",
    "                            batch_size = config[\"batch_size\"], \n",
    "                            collate_fn = validdata.collatefn)\n",
    "    # Start the training\n",
    "    \n",
    "    ## checkpoint\n",
    "    chk_callback = ModelCheckpoint(\n",
    "                        monitor = \"val_blosum_ratio\",\n",
    "                        mode    = \"max\",\n",
    "                        save_top_k = config[\"num_to_save\"], \n",
    "                        save_weights_only = True, \n",
    "                        dirpath = config[\"model_saveloc\"],\n",
    "                        filename = \"model-e{epoch:02d}-s{step:06d}-{val_blosum_ratio:.4f}\",\n",
    "                        save_on_train_epoch_end=False\n",
    "                    )\n",
    "    \n",
    "    trainer = L.Trainer(logger = wandb_logger, \n",
    "                        callbacks = [chk_callback],\n",
    "                        accumulate_grad_batches=config[\"accumulate_grad_batches\"],\n",
    "                        accelerator=\"gpu\", \n",
    "                        val_check_interval=0.25,\n",
    "                        devices=config[\"devices\"], strategy=\"auto\",  #before strategy=\"ddp\" -dpp is distributed (which does not work in notebook)\n",
    "                        max_epochs=config[\"epoch\"], \n",
    "                        gradient_clip_val = config[\"clip\"],\n",
    "                        gradient_clip_algorithm = \"value\")\n",
    "    \n",
    "    trainer.fit(rayltmodule, trainloader, \n",
    "                validloader)\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "828097c2-0a0f-40ab-abcf-fcfc312b4dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accumulate_grad_batches': 1,\n",
      " 'batch_size': 2,\n",
      " 'clip': 0.0001,\n",
      " 'crossentropylossratio': 1,\n",
      " 'devices': 1,\n",
      " 'epoch': 10,\n",
      " 'esm2_embedding_saveloc': None,\n",
      " 'log_wandb': False,\n",
      " 'lr': 2e-05,\n",
      " 'maxlength': 1500,\n",
      " 'minallowedlength': 55,\n",
      " 'model_saveloc': '/work/khs36/domino_model_tests/model_0',\n",
      " 'num_to_save': 3,\n",
      " 'reconstructionlossratio': 1,\n",
      " 'replicatelossratio': 1,\n",
      " 'trainfasta': '/hpc/home/khs36/projects/learn-plms/domino/DomInO/notebooks/model_0_sample_data/train_0.fasta',\n",
      " 'validfasta': '/hpc/home/khs36/projects/learn-plms/domino/DomInO/notebooks/model_0_sample_data/validation_0.fasta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/singhlab/user/khs36/tmp/ipykernel_2858554/3999500297.py:1: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize(config_path=\"configs\"):\n"
     ]
    }
   ],
   "source": [
    "with initialize(config_path=\"configs\"):\n",
    "    config = compose(config_name=\"train_0\")\n",
    "\n",
    "#main(config)  # Call your main function\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(OmegaConf.to_container(config, resolve=True))  # for display only\n",
    "\n",
    "#main(config)  # Call your main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5576e35-4e1e-4665-899f-2d84a52e108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-03 15:07:24,946 - __main__ - INFO - Running Raygun training...\n",
      "2025-10-03 15:07:24,946 - __main__ - INFO - Running Raygun training...\n",
      "2025-10-03 15:07:24,946 - __main__ - INFO - Running Raygun training...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/hpc/group/singhlab/user/khs36/micromamba/envs/raygun/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/hpc/group/singhlab/user/khs36/micromamba/envs/raygun/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py:259: Found unsupported keys in the lr scheduler dict: {'freq'}. HINT: remove them from the output of `configure_optimizers`.\n",
      "\n",
      "  | Name         | Type         | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model        | Raygun       | 701 M  | train\n",
      "1 | decodermodel | DecoderBlock | 13.5 M | train\n",
      "------------------------------------------------------\n",
      "701 M     Trainable params\n",
      "0         Non-trainable params\n",
      "701 M     Total params\n",
      "2,805.231 Total estimated model params size (MB)\n",
      "745       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/singhlab/user/khs36/micromamba/envs/raygun/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/hpc/group/singhlab/user/khs36/micromamba/envs/raygun/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  25%|██▌       | 2/8 [00:05<00:16,  0.36it/s, v_num=0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  9.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00,  8.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00,  8.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00,  7.92it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00,  7.86it/s]\u001b[A\n",
      "Epoch 0:  50%|█████     | 4/8 [00:26<00:26,  0.15it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 10.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 10.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.21it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.15it/s]\u001b[A\n",
      "Epoch 0:  75%|███████▌  | 6/8 [00:45<00:15,  0.13it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 10.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 10.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.34it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.32it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 8/8 [01:05<00:00,  0.12it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 12.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.09it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.09it/s]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 2/8 [00:00<00:02,  2.05it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 10.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.87it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.72it/s]\u001b[A\n",
      "Epoch 1:  50%|█████     | 4/8 [00:02<00:02,  1.56it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 10.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 10.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.84it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.90it/s]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 6/8 [00:04<00:01,  1.47it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.88it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.72it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 8/8 [00:05<00:00,  1.42it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 10.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 10.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.79it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.70it/s]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 2/8 [00:01<00:03,  1.64it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 10.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 10.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.72it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.63it/s]\u001b[A\n",
      "Epoch 2:  50%|█████     | 4/8 [00:02<00:02,  1.42it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 10.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 10.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.36it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.35it/s]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 6/8 [00:04<00:01,  1.34it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 10.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 10.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.28it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.13it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 8/8 [00:24<00:00,  0.33it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 10.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 10.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.30it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.28it/s]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 2/8 [00:01<00:03,  1.99it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 10.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 10.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 10.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.23it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.11it/s]\u001b[A\n",
      "Epoch 3:  50%|█████     | 4/8 [00:19<00:19,  0.20it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 10.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 10.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.43it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.43it/s]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 6/8 [00:39<00:13,  0.15it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 13.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 12.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.24it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.10it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 8/8 [00:57<00:00,  0.14it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 12.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 12.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.79it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.69it/s]\u001b[A\n",
      "Epoch 4:  25%|██▌       | 2/8 [00:00<00:02,  2.06it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 12.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 10.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 10.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.68it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.72it/s]\u001b[A\n",
      "Epoch 4:  50%|█████     | 4/8 [00:02<00:02,  1.65it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 13.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.22it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.37it/s]\u001b[A\n",
      "Epoch 4:  75%|███████▌  | 6/8 [00:04<00:01,  1.49it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.53it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.50it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 8/8 [00:23<00:00,  0.34it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 10.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 10.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.40it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.31it/s]\u001b[A\n",
      "Epoch 5:  25%|██▌       | 2/8 [00:00<00:02,  2.21it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 13.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 12.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 12.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 12.12it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 12.01it/s]\u001b[A\n",
      "Epoch 5:  50%|█████     | 4/8 [00:19<00:19,  0.20it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 13.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 12.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.43it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.35it/s]\u001b[A\n",
      "Epoch 5:  75%|███████▌  | 6/8 [00:38<00:12,  0.16it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 10.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 10.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.33it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.47it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 8/8 [00:57<00:00,  0.14it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 13.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 12.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.75it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.66it/s]\u001b[A\n",
      "Epoch 6:  25%|██▌       | 2/8 [00:00<00:02,  2.24it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 12.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.26it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.05it/s]\u001b[A\n",
      "Epoch 6:  50%|█████     | 4/8 [00:20<00:20,  0.20it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 13.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.14it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.11it/s]\u001b[A\n",
      "Epoch 6:  75%|███████▌  | 6/8 [00:21<00:07,  0.28it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 10.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.25it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.32it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 8/8 [00:23<00:00,  0.35it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 12.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.49it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.49it/s]\u001b[A\n",
      "Epoch 7:  25%|██▌       | 2/8 [00:01<00:03,  1.72it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 12.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 10.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.72it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.68it/s]\u001b[A\n",
      "Epoch 7:  50%|█████     | 4/8 [00:19<00:19,  0.20it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 12.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 10.81it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.81it/s]\u001b[A\n",
      "Epoch 7:  75%|███████▌  | 6/8 [00:38<00:12,  0.16it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 13.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 12.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.75it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.63it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 8/8 [00:55<00:00,  0.14it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 12.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 12.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 12.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.79it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.59it/s]\u001b[A\n",
      "Epoch 8:  25%|██▌       | 2/8 [00:00<00:02,  2.20it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 12.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 12.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.56it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.61it/s]\u001b[A\n",
      "Epoch 8:  50%|█████     | 4/8 [00:19<00:19,  0.21it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 13.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 12.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 12.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 12.49it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 12.41it/s]\u001b[A\n",
      "Epoch 8:  75%|███████▌  | 6/8 [00:20<00:06,  0.29it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 12.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.61it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.60it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 8/8 [00:38<00:00,  0.21it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 13.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 12.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 12.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.28it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.95it/s]\u001b[A\n",
      "Epoch 9:  25%|██▌       | 2/8 [00:00<00:02,  2.37it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 12.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 11.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 11.36it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 11.35it/s]\u001b[A\n",
      "Epoch 9:  50%|█████     | 4/8 [00:19<00:19,  0.20it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 13.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 12.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 12.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 12.34it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 12.41it/s]\u001b[A\n",
      "Epoch 9:  75%|███████▌  | 6/8 [00:37<00:12,  0.16it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 14.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 13.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 12.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 12.33it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 12.39it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 8/8 [00:55<00:00,  0.14it/s, v_num=0]       \u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 15.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 13.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 13.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 13.09it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 12.92it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 8/8 [01:11<00:00,  0.11it/s, v_num=0]       \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 8/8 [01:11<00:00,  0.11it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "new_raygun_model_0 = Raygun()\n",
    "rayltmodule = RaygunLightning(new_raygun_model_0)\n",
    "\n",
    "main(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d4338e-1d0b-4dc9-b79d-9a00a805273d",
   "metadata": {},
   "source": [
    "# Success!\n",
    "\n",
    "# Note that this can be a base line for my implementations - I need to create a modified data-loader and loss calculator that inputs the scrambled sequence and has an unscrambled version as the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6051ca1-3dfb-49d6-b6b0-7b99877a24ea",
   "metadata": {},
   "source": [
    "# Supplementary sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ad2cbe-a903-4f57-8bd1-880b926d8c05",
   "metadata": {},
   "source": [
    "# S1 Aside - Attention and multihead attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9bc1860-a356-41ab-a9ba-6960cf5bb5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGTZJREFUeJzt3X9sVYX9//HXpRduEctFkEL74QL9IJMfBcSWuQLOH2CTBvlqtjHdB1kdc1lnQbAxcdU/NPvBZcl3ixpnPysjnYRgyTJB/G6AJZPiYrqVaj8y9IMwiL0K2C8EbqGfebu25/vHN9zYMUrPad89nPp8JCfZvTnX80rDeHLvbXtDjuM4AgBggA3zewAAYGgiMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwER4sC/Y3d2tkydPKisrS6FQaLAvDwDoB8dxdOHCBeXm5mrYsN6fowx6YE6ePKlYLDbYlwUADKBEIqFJkyb1es6gByYrK0uSlPuLH2rYyMhgX75frn8/WHsvGXWq2+8JniWnBfNV3M5RwfwNTKM+CearClkfdfo9wbNPb8vwe4Ir3anP9NHGH6f/Lu/NoAfm0stiw0ZGNGxk5mBfvl8yIsEMTHh4cAOTEQlmYLozgxmYjBHBDEx4eHADMywzWIG5pC9vcQTz/70AgGsegQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmPAXmpZdeUl5enjIzM1VQUKC33nproHcBAALOdWC2b9+u9evX6+mnn9a7776r22+/XSUlJWppabHYBwAIKNeB+cUvfqHvfve7euSRRzRz5kw999xzisViqqqqstgHAAgoV4Hp6OhQU1OTiouLe9xfXFyst99++18+JpVKqa2trccBABj6XAXmzJkz6urq0oQJE3rcP2HCBJ0+ffpfPiYejysajaaPWCzmfS0AIDA8vckfCoV63HYc57L7LqmsrFQymUwfiUTCyyUBAAETdnPyjTfeqIyMjMuerbS2tl72rOaSSCSiSCTifSEAIJBcPYMZMWKECgoKVFdX1+P+uro6LVy4cECHAQCCzdUzGEmqqKjQqlWrVFhYqKKiIlVXV6ulpUVlZWUW+wAAAeU6MA888IDOnj2rH/3oRzp16pTy8/P1hz/8QVOmTLHYBwAIKNeBkaRHH31Ujz766EBvAQAMIfwuMgCACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGDC0+fBDIjOYf//CJB//19/83uCJ8dfm+b3BM86Zv6P3xM8mTvpE78neJL475v8nuBJ5v/5i98TPOv8RoHfE1zp/ntHn88N1t/wAIDAIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGDCdWAOHDig5cuXKzc3V6FQSDt37jSYBQAIOteBaW9v17x58/Tiiy9a7AEADBFhtw8oKSlRSUmJxRYAwBDiOjBupVIppVKp9O22tjbrSwIArgHmb/LH43FFo9H0EYvFrC8JALgGmAemsrJSyWQyfSQSCetLAgCuAeYvkUUiEUUiEevLAACuMfwcDADAhOtnMBcvXtSxY8fSt0+cOKHm5maNHTtWkydPHtBxAIDgch2YgwcP6q677krfrqiokCSVlpbqN7/5zYANAwAEm+vA3HnnnXIcx2ILAGAI4T0YAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYML158EMlKwPhisjMtyvy3ty+Ny/+z3Bk84vdfo9wbOJr2f6PcGT1n8E889K9zi/F3hzcU8wv96SdP0bEb8nuNKV6vvngfEMBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJV4GJx+NasGCBsrKylJ2drfvvv19Hjhyx2gYACDBXgamvr1d5ebkaGhpUV1enzs5OFRcXq7293WofACCgwm5O3rNnT4/bNTU1ys7OVlNTk7761a8O6DAAQLC5Csw/SyaTkqSxY8de8ZxUKqVUKpW+3dbW1p9LAgACwvOb/I7jqKKiQosXL1Z+fv4Vz4vH44pGo+kjFot5vSQAIEA8B2bNmjV677339Morr/R6XmVlpZLJZPpIJBJeLwkACBBPL5GtXbtWu3bt0oEDBzRp0qRez41EIopEIp7GAQCCy1VgHMfR2rVrtWPHDu3fv195eXlWuwAAAecqMOXl5dq2bZtee+01ZWVl6fTp05KkaDSqkSNHmgwEAASTq/dgqqqqlEwmdeeddyonJyd9bN++3WofACCgXL9EBgBAX/C7yAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMOHqA8cG0r+91qLwsIhfl/fkyLrJfk/wZMJbwf13RPTDC35P8OSzidf5PcGTc/l+L/Dm1Ztf8XuCZ0+VLvd7giud3R367z6eG9y/eQAA1zQCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADDhKjBVVVWaO3euRo8erdGjR6uoqEi7d++22gYACDBXgZk0aZI2btyogwcP6uDBg7r77rt133336fDhw1b7AAABFXZz8vLly3vc/ulPf6qqqio1NDRo9uzZAzoMABBsrgLzeV1dXfrtb3+r9vZ2FRUVXfG8VCqlVCqVvt3W1ub1kgCAAHH9Jv+hQ4d0/fXXKxKJqKysTDt27NCsWbOueH48Hlc0Gk0fsVisX4MBAMHgOjA333yzmpub1dDQoB/84AcqLS3V+++/f8XzKysrlUwm00cikejXYABAMLh+iWzEiBG66aabJEmFhYVqbGzU888/r1/96lf/8vxIJKJIJNK/lQCAwOn3z8E4jtPjPRYAACSXz2CeeuoplZSUKBaL6cKFC6qtrdX+/fu1Z88eq30AgIByFZhPP/1Uq1at0qlTpxSNRjV37lzt2bNH99xzj9U+AEBAuQrM5s2brXYAAIYYfhcZAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmXH3g2EA6sWqyMjIz/bq8J1/6zVm/J3jSOTpYX+fPS96c5fcET/7v/JDfEzwJdTl+T/DkgW3r/Z7g2fjbu/2e4ErnPz6TdvbtXJ7BAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACAiX4FJh6PKxQKaf369QM0BwAwVHgOTGNjo6qrqzV37tyB3AMAGCI8BebixYtauXKlNm3apBtuuGGgNwEAhgBPgSkvL9eyZcu0dOnSgd4DABgiwm4fUFtbq3feeUeNjY19Oj+VSimVSqVvt7W1ub0kACCAXD2DSSQSWrdunbZu3arMzMw+PSYejysajaaPWCzmaSgAIFhcBaapqUmtra0qKChQOBxWOBxWfX29XnjhBYXDYXV1dV32mMrKSiWTyfSRSCQGbDwA4Nrl6iWyJUuW6NChQz3u+853vqMZM2boySefVEZGxmWPiUQiikQi/VsJAAgcV4HJyspSfn5+j/tGjRqlcePGXXY/AOCLjZ/kBwCYcP1dZP9s//79AzADADDU8AwGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAAT/f7AMa/GHO1WeHi3X5f35NNFY/2e4EnyS47fEzzL+Czk9wRPxr8bzK/5mVuC+fV+/aH/7fcEzx5MPOH3BFe6Ovr+vIRnMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMuArMs88+q1Ao1OOYOHGi1TYAQICF3T5g9uzZ2rdvX/p2RkbGgA4CAAwNrgMTDod51gIAuCrX78EcPXpUubm5ysvL04MPPqjjx4/3en4qlVJbW1uPAwAw9LkKzG233aYtW7Zo79692rRpk06fPq2FCxfq7NmzV3xMPB5XNBpNH7FYrN+jAQDXPleBKSkp0de//nXNmTNHS5cu1e9//3tJ0ssvv3zFx1RWViqZTKaPRCLRv8UAgEBw/R7M540aNUpz5szR0aNHr3hOJBJRJBLpz2UAAAHUr5+DSaVS+uCDD5STkzNQewAAQ4SrwDzxxBOqr6/XiRMn9Oc//1nf+MY31NbWptLSUqt9AICAcvUS2ccff6xvfetbOnPmjMaPH6+vfOUramho0JQpU6z2AQACylVgamtrrXYAAIYYfhcZAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMOHq82AGUsY/HGXI8evynjQ9+59+T/Dkzr/e7/cEzz7+r2B+HHdnJOT3BE+iR/xe4M33P/wPvyd4dm5+p98TXOn+e9/38gwGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAnXgfnkk0/00EMPady4cbruuut0yy23qKmpyWIbACDAwm5OPnfunBYtWqS77rpLu3fvVnZ2tv72t79pzJgxRvMAAEHlKjA/+9nPFIvFVFNTk75v6tSpA70JADAEuHqJbNeuXSosLNSKFSuUnZ2t+fPna9OmTb0+JpVKqa2trccBABj6XAXm+PHjqqqq0vTp07V3716VlZXpscce05YtW674mHg8rmg0mj5isVi/RwMArn2uAtPd3a1bb71VGzZs0Pz58/X9739f3/ve91RVVXXFx1RWViqZTKaPRCLR79EAgGufq8Dk5ORo1qxZPe6bOXOmWlparviYSCSi0aNH9zgAAEOfq8AsWrRIR44c6XHfhx9+qClTpgzoKABA8LkKzOOPP66GhgZt2LBBx44d07Zt21RdXa3y8nKrfQCAgHIVmAULFmjHjh165ZVXlJ+frx//+Md67rnntHLlSqt9AICAcvVzMJJ077336t5777XYAgAYQvhdZAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmHD9gWMD5dSyf2jYyAy/Lu9JSfGDfk/w5LNbxvg9wbMxEb8XePM/E0N+T/BkRNLvBd6c2/Vvfk/w7IZOx+8JrnR1hPVxH8/lGQwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJhwFZipU6cqFApddpSXl1vtAwAEVNjNyY2Njerq6krf/utf/6p77rlHK1asGPBhAIBgcxWY8ePH97i9ceNGTZs2TXfccceAjgIABJ+rwHxeR0eHtm7dqoqKCoVCoSuel0qllEql0rfb2tq8XhIAECCe3+TfuXOnzp8/r4cffrjX8+LxuKLRaPqIxWJeLwkACBDPgdm8ebNKSkqUm5vb63mVlZVKJpPpI5FIeL0kACBAPL1E9tFHH2nfvn169dVXr3puJBJRJBLxchkAQIB5egZTU1Oj7OxsLVu2bKD3AACGCNeB6e7uVk1NjUpLSxUOe/4eAQDAEOc6MPv27VNLS4tWr15tsQcAMES4fgpSXFwsx3EstgAAhhB+FxkAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwMegfSXnps2S6/54a7Ev3W2dX8DZLUlfHZ35P8KwrFPJ7giddqYDu7vB7gTdOgP+p7HQF6/O1Lv190pfPBQs5g/zpYR9//LFisdhgXhIAMMASiYQmTZrU6zmDHpju7m6dPHlSWVlZCg3wv07b2toUi8WUSCQ0evToAf1vW2L34GL34AvqdnZfznEcXbhwQbm5uRo2rPenjoP+EtmwYcOuWr3+Gj16dKD+MFzC7sHF7sEX1O3s7ikajfbpvAC/cgkAuJYRGACAiSEVmEgkomeeeUaRSMTvKa6we3Cxe/AFdTu7+2fQ3+QHAHwxDKlnMACAaweBAQCYIDAAABMEBgBgYsgE5qWXXlJeXp4yMzNVUFCgt956y+9JV3XgwAEtX75cubm5CoVC2rlzp9+T+iQej2vBggXKyspSdna27r//fh05csTvWVdVVVWluXPnpn/4rKioSLt37/Z7lmvxeFyhUEjr16/3e0qvnn32WYVCoR7HxIkT/Z7VJ5988okeeughjRs3Ttddd51uueUWNTU1+T3rqqZOnXrZ1zwUCqm8vNyXPUMiMNu3b9f69ev19NNP691339Xtt9+ukpIStbS0+D2tV+3t7Zo3b55efPFFv6e4Ul9fr/LycjU0NKiurk6dnZ0qLi5We3u739N6NWnSJG3cuFEHDx7UwYMHdffdd+u+++7T4cOH/Z7WZ42NjaqurtbcuXP9ntIns2fP1qlTp9LHoUOH/J50VefOndOiRYs0fPhw7d69W++//75+/vOfa8yYMX5Pu6rGxsYeX++6ujpJ0ooVK/wZ5AwBX/7yl52ysrIe982YMcP54Q9/6NMi9yQ5O3bs8HuGJ62trY4kp76+3u8prt1www3Or3/9a79n9MmFCxec6dOnO3V1dc4dd9zhrFu3zu9JvXrmmWecefPm+T3DtSeffNJZvHix3zMGxLp165xp06Y53d3dvlw/8M9gOjo61NTUpOLi4h73FxcX6+233/Zp1RdLMpmUJI0dO9bnJX3X1dWl2tpatbe3q6ioyO85fVJeXq5ly5Zp6dKlfk/ps6NHjyo3N1d5eXl68MEHdfz4cb8nXdWuXbtUWFioFStWKDs7W/Pnz9emTZv8nuVaR0eHtm7dqtWrVw/4Lxbuq8AH5syZM+rq6tKECRN63D9hwgSdPn3ap1VfHI7jqKKiQosXL1Z+fr7fc67q0KFDuv766xWJRFRWVqYdO3Zo1qxZfs+6qtraWr3zzjuKx+N+T+mz2267TVu2bNHevXu1adMmnT59WgsXLtTZs2f9ntar48ePq6qqStOnT9fevXtVVlamxx57TFu2bPF7mis7d+7U+fPn9fDDD/u2YdB/m7KVfy604zi+VfuLZM2aNXrvvff0pz/9ye8pfXLzzTerublZ58+f1+9+9zuVlpaqvr7+mo5MIpHQunXr9MYbbygzM9PvOX1WUlKS/t9z5sxRUVGRpk2bppdfflkVFRU+Lutdd3e3CgsLtWHDBknS/PnzdfjwYVVVVenb3/62z+v6bvPmzSopKVFubq5vGwL/DObGG29URkbGZc9WWltbL3tWg4G1du1a7dq1S2+++ab5RzAMlBEjRuimm25SYWGh4vG45s2bp+eff97vWb1qampSa2urCgoKFA6HFQ6HVV9frxdeeEHhcFhdXV1+T+yTUaNGac6cOTp69KjfU3qVk5Nz2T84Zs6cec1/09DnffTRR9q3b58eeeQRX3cEPjAjRoxQQUFB+rslLqmrq9PChQt9WjW0OY6jNWvW6NVXX9Uf//hH5eXl+T3JM8dxlEpd2x+FvWTJEh06dEjNzc3po7CwUCtXrlRzc7MyMjL8ntgnqVRKH3zwgXJycvye0qtFixZd9m33H374oaZMmeLTIvdqamqUnZ2tZcuW+bpjSLxEVlFRoVWrVqmwsFBFRUWqrq5WS0uLysrK/J7Wq4sXL+rYsWPp2ydOnFBzc7PGjh2ryZMn+7isd+Xl5dq2bZtee+01ZWVlpZ89RqNRjRw50ud1V/bUU0+ppKREsVhMFy5cUG1trfbv3689e/b4Pa1XWVlZl72/NWrUKI0bN+6aft/riSee0PLlyzV58mS1trbqJz/5idra2lRaWur3tF49/vjjWrhwoTZs2KBvfvOb+stf/qLq6mpVV1f7Pa1Puru7VVNTo9LSUoXDPv8V78v3rhn45S9/6UyZMsUZMWKEc+uttwbiW2bffPNNR9JlR2lpqd/TevWvNktyampq/J7Wq9WrV6f/jIwfP95ZsmSJ88Ybb/g9y5MgfJvyAw884OTk5DjDhw93cnNzna997WvO4cOH/Z7VJ6+//rqTn5/vRCIRZ8aMGU51dbXfk/ps7969jiTnyJEjfk9x+HX9AAATgX8PBgBwbSIwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATPw/ioHWqtkZXoQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "below after scaling and softmax\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "below without any scaling\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Output (with scaling)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# toy setup\n",
    "seq_len = 8      # number of tokens\n",
    "d_model = 12     # embedding dimension\n",
    "d_head = d_model # since only 1 head, head dim = model dim\n",
    "\n",
    "# random embeddings for 8 tokens\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(seq_len, d_model)  # shape (8, 12)\n",
    "\n",
    "# random query/key projection matrices\n",
    "W_Q = np.random.randn(d_model, d_head)\n",
    "W_K = np.random.randn(d_model, d_head)\n",
    "\n",
    "# compute raw queries and keys\n",
    "Q = X @ W_Q  # shape (8, 12)\n",
    "K = X @ W_K  # shape (8, 12)\n",
    "\n",
    "# compute attention scores\n",
    "scores = Q @ K.T / np.sqrt(d_head)  # scaled dot-product, shape (8, 8) \n",
    "#- so that softmax doest produce only near the horizontal regions the scaling is applied\n",
    "\n",
    "# apply softmax to get attention weights\n",
    "attention_weights = np.exp(scores)\n",
    "attention_weights /= attention_weights.sum(axis=1, keepdims=True)  # shape (8, 8)\n",
    "\n",
    "# then multiply by v\n",
    "\n",
    "# random value projection matrix\n",
    "W_V = np.random.randn(d_model, d_head)\n",
    "\n",
    "# compute values\n",
    "V = X @ W_V  # shape (8, 12)\n",
    "\n",
    "# compute attention output\n",
    "Z = attention_weights @ V  # shape (8, 12)\n",
    "\n",
    "# With multihead attention you have many of these Z (each made from it's own W_Q, W_K and W_V. \n",
    "# These are then concatenated against eachother\n",
    "\n",
    "plt.imshow(Q)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(K)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(Q @ K.T)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"below after scaling and softmax\")\n",
    "\n",
    "plt.imshow(attention_weights)\n",
    "plt.show()\n",
    "\n",
    "print(\"below without any scaling\")\n",
    "no_scale = np.exp(Q @ K.T)\n",
    "no_scale/=no_scale.sum(axis=1, keepdims=True)  # shape (8, 8)\n",
    "\n",
    "plt.imshow(no_scale)\n",
    "plt.show()\n",
    "\n",
    "print(\"Final Output (with scaling)\")\n",
    "\n",
    "plt.imshow(Z)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a717c4f-4150-4fed-bc3e-02bff8eb2fb4",
   "metadata": {},
   "source": [
    "# S2 Aside - Rope - Rotary positional embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e22db4a-799e-4152-969d-ce0079591125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read through the below and look at the print statement outputs when called to understand\n",
    "def apply_rope(x, position, d_model):\n",
    "    \"\"\"\n",
    "    Apply RoPE to a single vector x at given position.\n",
    "    x: shape (d_model,)\n",
    "    position: integer position\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'x = {x}')\n",
    "    print(f'position = {position}')\n",
    "    print(f'd_model = {d_model}')\n",
    "\n",
    "\n",
    "    half = d_model // 2\n",
    "    print(f'half = {half}')\n",
    "    freqs = np.exp(np.linspace(0., -1., half) * np.log(10000.))  # frequencies\n",
    "    print(f'freqs = {freqs}')\n",
    "    print(f'position = {position}')\n",
    "    print(f'position * freqs = {position * freqs}')\n",
    "    angles = position * freqs\n",
    "    print(f'angles = {angles}')\n",
    "\n",
    "    x_out = np.zeros_like(x)\n",
    "    print(f'x_out = {x_out}')\n",
    "    for i in range(half):\n",
    "        cos, sin = np.cos(angles[i]), np.sin(angles[i])\n",
    "        xi, xj = x[2*i], x[2*i+1]\n",
    "\n",
    "        # 2D rotation\n",
    "        x_out[2*i]   = xi * cos - xj * sin\n",
    "        x_out[2*i+1] = xi * sin + xj * cos\n",
    "    print(f'initial x = {x}')\n",
    "    print(f'x_out final = {x_out}')\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbfccc97-b0be-443b-8646-99e65c04ee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [-1.55586203 -2.00061881 -1.11869452  0.53628058 -2.11092356  4.39854111\n",
      " -0.11008244  0.28464758  1.15150177  2.50753788 -4.09651954  5.00397048]\n",
      "position = 0\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 0\n",
      "position * freqs = [0. 0. 0. 0. 0. 0.]\n",
      "angles = [0. 0. 0. 0. 0. 0.]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [-1.55586203 -2.00061881 -1.11869452  0.53628058 -2.11092356  4.39854111\n",
      " -0.11008244  0.28464758  1.15150177  2.50753788 -4.09651954  5.00397048]\n",
      "x_out final = [-1.55586203 -2.00061881 -1.11869452  0.53628058 -2.11092356  4.39854111\n",
      " -0.11008244  0.28464758  1.15150177  2.50753788 -4.09651954  5.00397048]\n",
      "x = [-0.80649223 -2.41419155  3.47110607  0.83344127  0.94057406  0.69001062\n",
      "  1.92252705 -3.77551795  5.43665565 -1.98965679  0.10453218  4.8056732 ]\n",
      "position = 0\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 0\n",
      "position * freqs = [0. 0. 0. 0. 0. 0.]\n",
      "angles = [0. 0. 0. 0. 0. 0.]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [-0.80649223 -2.41419155  3.47110607  0.83344127  0.94057406  0.69001062\n",
      "  1.92252705 -3.77551795  5.43665565 -1.98965679  0.10453218  4.8056732 ]\n",
      "x_out final = [-0.80649223 -2.41419155  3.47110607  0.83344127  0.94057406  0.69001062\n",
      "  1.92252705 -3.77551795  5.43665565 -1.98965679  0.10453218  4.8056732 ]\n",
      "x = [ 0.06579366  0.16162408  6.11359683  3.289503   -2.79922633 -9.6258085\n",
      " -2.32475745 -3.30284082  5.06566157  3.66402854  5.2866799  -3.89252958]\n",
      "position = 1\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 1\n",
      "position * freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "angles = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [ 0.06579366  0.16162408  6.11359683  3.289503   -2.79922633 -9.6258085\n",
      " -2.32475745 -3.30284082  5.06566157  3.66402854  5.2866799  -3.89252958]\n",
      "x_out final = [-0.10045351  0.14268932  5.51780291  4.21316357 -2.55657933 -9.69307791\n",
      " -2.31159022 -3.31206965  5.06334871  3.66722403  5.28706913 -3.8920009 ]\n",
      "x = [-6.8822367   0.23136772 -4.74130881  3.334564   -5.52444766 -0.64914957\n",
      " -7.3205504   4.06966735 -1.4226503   2.54008209  6.98126262 -2.02391464]\n",
      "position = 1\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 1\n",
      "position * freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "angles = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [-6.8822367   0.23136772 -4.74130881  3.334564   -5.52444766 -0.64914957\n",
      " -7.3205504   4.06966735 -1.4226503   2.54008209  6.98126262 -2.02391464]\n",
      "x_out final = [-3.91317759 -5.66619398 -5.20816824  2.54446652 -5.50640072 -0.78769805\n",
      " -7.33669398  4.04049154 -1.4242527   2.53918395  6.98146498 -2.02321651]\n",
      "x = [ 0.85589533 -0.68343296 -2.58822546  3.5611947   0.72616903 -6.2482494\n",
      " -0.82492479 -3.22787778 -0.32386341 -3.24790209  0.37684516 -2.94002503]\n",
      "position = 2\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 2\n",
      "position * freqs = [2.00000000e+00 3.16978638e-01 5.02377286e-02 7.96214341e-03\n",
      " 1.26191469e-03 2.00000000e-04]\n",
      "angles = [2.00000000e+00 3.16978638e-01 5.02377286e-02 7.96214341e-03\n",
      " 1.26191469e-03 2.00000000e-04]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [ 0.85589533 -0.68343296 -2.58822546  3.5611947   0.72616903 -6.2482494\n",
      " -0.82492479 -3.22787778 -0.32386341 -3.24790209  0.37684516 -2.94002503]\n",
      "x_out final = [ 0.2652657   1.06267188 -3.56929818  2.57703884  1.03901869 -6.20390056\n",
      " -0.79919809 -3.23434356 -0.31976458 -3.24830819  0.37743316 -2.9399496 ]\n",
      "x = [-1.82810953 -0.49368598 -4.08203854  2.2624686   1.05553542  0.61993831\n",
      " -4.03238654  2.69869031 -1.08773796 -2.31212608  5.56464758 -1.20876596]\n",
      "position = 2\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 2\n",
      "position * freqs = [2.00000000e+00 3.16978638e-01 5.02377286e-02 7.96214341e-03\n",
      " 1.26191469e-03 2.00000000e-04]\n",
      "angles = [2.00000000e+00 3.16978638e-01 5.02377286e-02 7.96214341e-03\n",
      " 1.26191469e-03 2.00000000e-04]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [-1.82810953 -0.49368598 -4.08203854  2.2624686   1.05553542  0.61993831\n",
      " -4.03238654  2.69869031 -1.08773796 -2.31212608  5.56464758 -1.20876596]\n",
      "x_out final = [ 1.20966939 -1.45684944 -4.58388252  0.87739606  1.02307251  0.67216157\n",
      " -4.05374586  2.66649867 -1.08481939 -2.31349687  5.56488922 -1.207653  ]\n",
      "x = [ -1.07599697   5.84973952  -0.15052857   0.5080377   -1.13468726\n",
      " -10.6173196    3.4434625    2.0782934   -3.2760172    2.22838622\n",
      "  -1.68369747  -2.97354897]\n",
      "position = 3\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 3\n",
      "position * freqs = [3.00000000e+00 4.75467958e-01 7.53565929e-02 1.19432151e-02\n",
      " 1.89287203e-03 3.00000000e-04]\n",
      "angles = [3.00000000e+00 4.75467958e-01 7.53565929e-02 1.19432151e-02\n",
      " 1.89287203e-03 3.00000000e-04]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [ -1.07599697   5.84973952  -0.15052857   0.5080377   -1.13468726\n",
      " -10.6173196    3.4434625    2.0782934   -3.2760172    2.22838622\n",
      "  -1.68369747  -2.97354897]\n",
      "x_out final = [  0.23971364  -5.94304293  -0.3663883    0.38278032  -0.33213904\n",
      " -10.67261329   3.418396     2.11927021  -3.28022938   2.22218115\n",
      "  -1.68280533  -2.97405394]\n",
      "x = [-0.64422428  0.1444011   1.89515897  1.22836443 -1.62968548  1.90129378\n",
      " -0.25903488  0.29200152  1.56135297 -0.2821525   7.37839877  4.04804006]\n",
      "position = 3\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 3\n",
      "position * freqs = [3.00000000e+00 4.75467958e-01 7.53565929e-02 1.19432151e-02\n",
      " 1.89287203e-03 3.00000000e-04]\n",
      "angles = [3.00000000e+00 4.75467958e-01 7.53565929e-02 1.19432151e-02\n",
      " 1.89287203e-03 3.00000000e-04]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [-0.64422428  0.1444011   1.89515897  1.22836443 -1.62968548  1.90129378\n",
      " -0.25903488  0.29200152  1.56135297 -0.2821525   7.37839877  4.04804006]\n",
      "x_out final = [ 0.61739932 -0.23386894  1.12265589  1.95963018 -1.76819995  1.77320662\n",
      " -0.26250376  0.28888706  1.56188425 -0.27919655  7.37718403  4.05025339]\n",
      "x = [ 0.90062337 -0.15092975  1.20966156 -0.42531881  0.05587937 -4.93090021\n",
      "  2.94566624  0.22388246 -2.50231936  1.58644185 -3.07022982  3.28676263]\n",
      "position = 4\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 4\n",
      "position * freqs = [4.00000000e+00 6.33957277e-01 1.00475457e-01 1.59242868e-02\n",
      " 2.52382938e-03 4.00000000e-04]\n",
      "angles = [4.00000000e+00 6.33957277e-01 1.00475457e-01 1.59242868e-02\n",
      " 2.52382938e-03 4.00000000e-04]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [ 0.90062337 -0.15092975  1.20966156 -0.42531881  0.05587937 -4.93090021\n",
      "  2.94566624  0.22388246 -2.50231936  1.58644185 -3.07022982  3.28676263]\n",
      "x_out final = [-0.70291073 -0.58293974  1.22654433  0.37385316  0.55019883 -4.90042657\n",
      "  2.94172775  0.27075973 -2.5063153   1.58012137 -3.07154428  3.28553427]\n",
      "x = [-2.45282502 -0.46684356  7.9986725   1.7034712   0.34253902  0.57293503\n",
      "  1.78411612 -2.4903929   1.30691106 -0.29586738  3.45434241  5.39985448]\n",
      "position = 4\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 4\n",
      "position * freqs = [4.00000000e+00 6.33957277e-01 1.00475457e-01 1.59242868e-02\n",
      " 2.52382938e-03 4.00000000e-04]\n",
      "angles = [4.00000000e+00 6.33957277e-01 1.00475457e-01 1.59242868e-02\n",
      " 2.52382938e-03 4.00000000e-04]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [-2.45282502 -0.46684356  7.9986725   1.7034712   0.34253902  0.57293503\n",
      "  1.78411612 -2.4903929   1.30691106 -0.29586738  3.45434241  5.39985448]\n",
      "x_out final = [ 1.24996505  2.16145341  5.43541842  6.11038481  0.28334236  0.60440437\n",
      "  1.82354597 -2.46166757  1.30765361 -0.29256802  3.45218219  5.40123578]\n",
      "x = [ 3.17975327  1.91444303 -5.29809168  0.34506979  0.09288418 -4.40003346\n",
      "  5.75074785  0.70937994 -4.1666524  -1.3966713   3.04688915  2.94870024]\n",
      "position = 5\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 5\n",
      "position * freqs = [5.00000000e+00 7.92446596e-01 1.25594322e-01 1.99053585e-02\n",
      " 3.15478672e-03 5.00000000e-04]\n",
      "angles = [5.00000000e+00 7.92446596e-01 1.25594322e-01 1.99053585e-02\n",
      " 3.15478672e-03 5.00000000e-04]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [ 3.17975327  1.91444303 -5.29809168  0.34506979  0.09288418 -4.40003346\n",
      "  5.75074785  0.70937994 -4.1666524  -1.3966713   3.04688915  2.94870024]\n",
      "x_out final = [ 2.73778166 -2.5060875  -3.965533   -3.53035362  0.6433201  -4.35374105\n",
      "  5.73548906  0.82370254 -4.16222547 -1.40980923  3.04541442  2.95022331]\n",
      "x = [ 0.6466082   1.46977634  3.28434201  0.74768828  1.50141805  1.18563004\n",
      "  2.1905584   0.20687709 -4.38485786  0.46271628 -0.11351743 -0.36505699]\n",
      "position = 5\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 5\n",
      "position * freqs = [5.00000000e+00 7.92446596e-01 1.25594322e-01 1.99053585e-02\n",
      " 3.15478672e-03 5.00000000e-04]\n",
      "angles = [5.00000000e+00 7.92446596e-01 1.25594322e-01 1.99053585e-02\n",
      " 3.15478672e-03 5.00000000e-04]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [ 0.6466082   1.46977634  3.28434201  0.74768828  1.50141805  1.18563004\n",
      "  2.1905584   0.20687709 -4.38485786  0.46271628 -0.11351743 -0.36505699]\n",
      "x_out final = [ 1.5928225  -0.20312833  1.77354505  2.8636477   1.34107474  1.36436552\n",
      "  2.18600675  0.25043708 -4.38629581  0.44888071 -0.11333489 -0.3651137 ]\n",
      "x = [-5.66482522  3.44318499 -5.33053737  3.67589748  2.51300556 -4.81111091\n",
      "  1.82922215 -0.58669672  1.82855462  5.213466    5.19206827 -2.93453433]\n",
      "position = 6\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 6\n",
      "position * freqs = [6.00000000e+00 9.50935915e-01 1.50713186e-01 2.38864302e-02\n",
      " 3.78574407e-03 6.00000000e-04]\n",
      "angles = [6.00000000e+00 9.50935915e-01 1.50713186e-01 2.38864302e-02\n",
      " 3.78574407e-03 6.00000000e-04]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [-5.66482522  3.44318499 -5.33053737  3.67589748  2.51300556 -4.81111091\n",
      "  1.82922215 -0.58669672  1.82855462  5.213466    5.19206827 -2.93453433]\n",
      "x_out final = [-4.47711761  4.88888388 -6.0886559  -2.20343377  3.20687469 -4.37926248\n",
      "  1.84271309 -0.54283993  1.80880472  5.22035106  5.19382806 -2.93141856]\n",
      "x = [  6.46191546   8.75876978 -10.29443817   2.48635244   3.10317521\n",
      "  -2.93067285  -2.92197767   6.05851544  -2.3582368   -1.23699215\n",
      "  -2.88673304  -1.12995063]\n",
      "position = 6\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 6\n",
      "position * freqs = [6.00000000e+00 9.50935915e-01 1.50713186e-01 2.38864302e-02\n",
      " 3.78574407e-03 6.00000000e-04]\n",
      "angles = [6.00000000e+00 9.50935915e-01 1.50713186e-01 2.38864302e-02\n",
      " 3.78574407e-03 6.00000000e-04]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [  6.46191546   8.75876978 -10.29443817   2.48635244   3.10317521\n",
      "  -2.93067285  -2.92197767   6.05851544  -2.3582368   -1.23699215\n",
      "  -2.88673304  -1.12995063]\n",
      "x_out final = [ 8.65187524  6.60435117 -8.00405127 -6.9348806   3.5080192  -2.43153059\n",
      " -3.06584667  5.98699817 -2.35353698 -1.24591094 -2.88605455 -1.13168246]\n",
      "x = [ 3.05942699 -1.64477522  1.82952308  0.06615615 -0.12944343  2.29027434\n",
      " -2.9531727  -0.885761    2.93465224 -2.31585541 -3.95158727  0.23717243]\n",
      "position = 7\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 7\n",
      "position * freqs = [7.00000000e+00 1.10942523e+00 1.75832050e-01 2.78675019e-02\n",
      " 4.41670141e-03 7.00000000e-04]\n",
      "angles = [7.00000000e+00 1.10942523e+00 1.75832050e-01 2.78675019e-02\n",
      " 4.41670141e-03 7.00000000e-04]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [ 3.05942699 -1.64477522  1.82952308  0.06615615 -0.12944343  2.29027434\n",
      " -2.9531727  -0.885761    2.93465224 -2.31585541 -3.95158727  0.23717243]\n",
      "x_out final = [ 3.38710418  0.77000278  0.75522118  1.66768471 -0.52807937  2.23231815\n",
      " -2.92734531 -0.96770398  2.94485202 -2.30287138 -3.95175232  0.23440626]\n",
      "x = [-3.57097848 -4.52895197  0.11334179  0.32837453 -0.30954718  0.92185788\n",
      " -0.97011865 -0.53769239  2.2182198  -0.68267373  6.02976596  2.51276785]\n",
      "position = 7\n",
      "d_model = 12\n",
      "half = 6\n",
      "freqs = [1.00000000e+00 1.58489319e-01 2.51188643e-02 3.98107171e-03\n",
      " 6.30957344e-04 1.00000000e-04]\n",
      "position = 7\n",
      "position * freqs = [7.00000000e+00 1.10942523e+00 1.75832050e-01 2.78675019e-02\n",
      " 4.41670141e-03 7.00000000e-04]\n",
      "angles = [7.00000000e+00 1.10942523e+00 1.75832050e-01 2.78675019e-02\n",
      " 4.41670141e-03 7.00000000e-04]\n",
      "x_out = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "initial x = [-3.57097848 -4.52895197  0.11334179  0.32837453 -0.30954718  0.92185788\n",
      " -0.97011865 -0.53769239  2.2182198  -0.68267373  6.02976596  2.51276785]\n",
      "x_out final = [ 0.28329202 -5.7604721  -0.24358359  0.24767566 -0.4660326   0.85349576\n",
      " -0.95475977 -0.5645149   2.22121332 -0.67286989  6.02800555  2.51698807]\n"
     ]
    }
   ],
   "source": [
    "Q_rope = np.zeros_like(Q)\n",
    "K_rope = np.zeros_like(K)\n",
    "\n",
    "for pos in range(seq_len):\n",
    "    Q_rope[pos] = apply_rope(Q[pos], pos, d_model)\n",
    "    K_rope[pos] = apply_rope(K[pos], pos, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c8b3c5e-20bb-4226-8ac7-bb5bf7c93c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw query for token 0: [-1.55586203 -2.00061881 -1.11869452  0.53628058]\n",
      "RoPE query for token 0: [-1.55586203 -2.00061881 -1.11869452  0.53628058]\n",
      "RoPE query for token 1: [-0.10045351  0.14268932  5.51780291  4.21316357]\n"
     ]
    }
   ],
   "source": [
    "# attention scores with RoPE\n",
    "scores_rope = Q_rope @ K_rope.T / np.sqrt(d_head)\n",
    "\n",
    "# softmax along keys\n",
    "attn_weights_rope = np.exp(scores_rope) / np.exp(scores_rope).sum(axis=-1, keepdims=True)\n",
    "\n",
    "print(\"Raw query for token 0:\", Q[0][:12])\n",
    "print(\"RoPE query for token 0:\", Q_rope[0][:12])\n",
    "print(\"RoPE query for token 1:\", Q_rope[1][:12])\n",
    "\n",
    "correct / reword the below later\n",
    "\n",
    "# In essence if you think of each embedding row as a vector in n dimensional space,\n",
    "# rotary position embeddings rotate the vectors. \n",
    "# If they are near eachother they get rotated a similar amount, \n",
    "# if they are far apart, they get rotated different amounts widening the gap.\n",
    "# When you do Q_rope @ K_rope.T / np.sqrt(d_head) you get pairwise weights. - similarity of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d59e0ce-6168-4c2d-a463-bb622d3fab7a",
   "metadata": {},
   "source": [
    "# Convolution layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9b29c-896a-45fe-a3a2-2a1f40495dfd",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=XBF9iqt0CnA\n",
    "\n",
    "Convolutions help extract important features - write some more about here to summarise\n",
    "\n",
    "https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.conv1d.html#torch.nn.functional.conv1d\n",
    "\n",
    "https://www.youtube.com/shorts/s3kfsJ55BKQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e259fdaf-36fb-4d31-a75d-958474b156bb",
   "metadata": {},
   "source": [
    "# Silu and Gelu - activation functions can also include relu sigmoid, softmax,  etc.\n",
    "\n",
    "https://medium.com/@gauravnair/the-spark-your-neural-network-needs-understanding-the-significance-of-activation-functions-6b82d5f27fbf#c1ac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a4fda-b3fe-4a84-b3a1-9a971f2962f6",
   "metadata": {},
   "source": [
    "# Dustbin or consideration code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d22623-e41b-42a1-9bc0-d78e9ccc42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils - modelv2\n",
    "\n",
    "class ConvMasked(nn.Module):\n",
    "    \"\"\"\n",
    "    Applied modifications on Conv1d to make the masking work\n",
    "    \"\"\"\n",
    "    def __init__(self, indim, outdim, kernel_size):\n",
    "        super(ConvMasked, self).__init__()\n",
    "        self.conv        = nn.Conv1d(indim, outdim, \n",
    "                                    kernel_size = kernel_size, padding = \"valid\")\n",
    "        self.kernel_size = kernel_size\n",
    "        self.indim       = indim\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        batch, _, _ = x.shape\n",
    "        padding = torch.zeros(batch, self.indim, self.kernel_size - 1).to(x.device)\n",
    "        x1      = torch.concat([x, padding], dim = 2)\n",
    "        y       =  self.conv(x1)\n",
    "        if mask is not None:\n",
    "            y   = y * mask.unsqueeze(1) # unsqueeze the seequence part\n",
    "        return y\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, dim, convkernel):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.c1 = ConvMasked(dim     , dim // 2, kernel_size=convkernel)\n",
    "        self.s1 = nn.SiLU()\n",
    "        self.c2 = ConvMasked(dim // 2, dim // 4, kernel_size=convkernel // 2)\n",
    "        self.s2 = nn.SiLU()\n",
    "        self.c3 = ConvMasked(dim // 4, dim // 2, kernel_size=convkernel)\n",
    "        self.s3 = nn.SiLU()\n",
    "        return\n",
    "    \n",
    "    def forward(self, x, mask = None): \n",
    "        x = rearrange(x, \"b n c -> b c n\")\n",
    "        if mask is not None:\n",
    "            x = x * mask.unsqueeze(1)\n",
    "        x = self.s1(self.c1(x, mask))\n",
    "        x = self.s2(self.c2(x, mask))\n",
    "        x = self.s3(self.c3(x, mask))\n",
    "        x = rearrange(x, \"b c n -> b n c\")\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim = 2560, attnheads = 5, convkernel = 7):\n",
    "        super(Block, self).__init__()\n",
    "        self.encoder = TransformerLayer(embed_dim = dim, \n",
    "                                       ffn_embed_dim = 2 * dim,\n",
    "                                       attention_heads = attnheads,\n",
    "                                       use_rotary_embeddings = True)\n",
    "        \n",
    "        self.convblock = ConvBlock(dim, convkernel)\n",
    "        self.final = nn.Linear(dim // 2, dim)\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        x    = rearrange(x, \"b n c -> n b c\")\n",
    "        x, _ = self.encoder(x, self_attn_padding_mask = ~mask if mask is not None else mask) \n",
    "        x    = rearrange(x, \"n b c -> b n c\")\n",
    "\n",
    "        x    = self.convblock(x, mask = mask)\n",
    "        \n",
    "        return self.final(x)\n",
    "    \n",
    "    \n",
    "class BlockP(nn.Module):\n",
    "    def __init__(self, dim = 2560, attnheads = 5, convkernel = 7):\n",
    "        \"\"\"\n",
    "        Obsolete \n",
    "        \"\"\"\n",
    "        super(BlockP, self).__init__()\n",
    "        self.encoder = TransformerLayer(embed_dim = dim, \n",
    "                                       ffn_embed_dim = 2 * dim,\n",
    "                                       attention_heads = attnheads,\n",
    "                                        use_rotary_embeddings = True\n",
    "                                       )\n",
    "        self.convblock = nn.Sequential(Rearrange(\"b n c -> b c n\"),\n",
    "                                       nn.Conv1d(dim, dim // 2, kernel_size = convkernel, padding = \"same\"),\n",
    "                                       nn.SiLU(),\n",
    "                                       nn.Conv1d(dim // 2, dim // 4, kernel_size = convkernel // 2, padding = \"same\"), \n",
    "                                       nn.SiLU(),\n",
    "                                       nn.Conv1d(dim // 4, dim // 2, kernel_size = convkernel, padding = \"same\"),    \n",
    "                                       Rearrange(\"b c n -> b n c\"), \n",
    "                                       # nn.GELU(),\n",
    "                                    )\n",
    "        self.final = nn.Linear(dim // 2, dim)\n",
    "        # self.norm1 = nn.LayerNorm(dim // 2)\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        \"\"\"\n",
    "        This is an older Block version which does not use mask. \n",
    "        \"\"\"\n",
    "        batch, seq, len = x.shape\n",
    "        assert batch == 1, \"Batch should be equal to one for this obsolete class\"\n",
    "        x = rearrange(x, \"b n c -> n b c\")\n",
    "        x, _ = self.encoder(x)\n",
    "        x = rearrange(x, \"n b c -> b n c\")\n",
    "        x = self.convblock(x)\n",
    "        # x = self.norm1(x)\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7168dc44-199a-4bba-b3de-c0de100d65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From raygun file (model vs2)\n",
    "class RaygunEncoder(nn.Module):\n",
    "    def __init__(self, dim = 1280, reduction = 50,\n",
    "                 convkernel = 7,\n",
    "                 nhead = 20, numencoders = 2, dropout = 0.2,\n",
    "                 activation = \"gelu\"):\n",
    "        super(RaygunEncoder, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.encoders = nn.ModuleList()\n",
    "        for i in range(numencoders):\n",
    "            self.encoders.append(Block(dim = dim, \n",
    "                                       convkernel = convkernel, \n",
    "                                       attnheads = nhead))\n",
    "\n",
    "\n",
    "        self.redlength = reduction\n",
    "        self.reduction = Reduction(reduce_size = reduction)\n",
    "        self.final     = nn.Sequential(\n",
    "                            nn.Linear(dim * (numencoders+1), dim // (numencoders + 1) * 4),\n",
    "                            nn.SiLU(),\n",
    "                            nn.Linear(dim // (numencoders + 1) * 4, dim)\n",
    "                         )\n",
    "\n",
    "        nn.init.xavier_uniform_(self.final[0].weight, gain=1e-3)\n",
    "        nn.init.xavier_uniform_(self.final[2].weight, gain=1e-3)\n",
    "        nn.init.constant_(self.final[0].bias, 0)\n",
    "        nn.init.constant_(self.final[2].bias, 0)\n",
    "\n",
    "    def reduce(self, x, mask = None, noise = None):\n",
    "        \"\"\"\n",
    "        Use the Reduction operation to compress the PLM representation to a fixed-dimension space.\n",
    "        \"\"\"\n",
    "        batch, _, _ = x.shape\n",
    "        if noise is not None:\n",
    "            redmean, redstd = self.reduction(x, mask = mask, getstd = True)\n",
    "            reduced = redmean + torch.randn_like(redstd, device = x.device) * redstd * noise\n",
    "        else:\n",
    "            reduced = self.reduction(x, mask = mask, getstd = False)\n",
    "        return reduced\n",
    "\n",
    "    def forward(self, x, mask = None, noise = None):\n",
    "        \"\"\"\n",
    "        If error_c is provided, noise component is incorporated into the \n",
    "        fixed-dimensional representation. \n",
    "        \"\"\"\n",
    "        enc = self.reduce(x, mask = mask, noise = noise)\n",
    "        residues = [enc]\n",
    "        for mod in self.encoders:\n",
    "            xresidue = mod(x, mask = mask)\n",
    "            residue  = mod(self.reduce(xresidue, mask = mask, noise = noise)) # \n",
    "            x        = x + xresidue\n",
    "            residues.append(residue)\n",
    "\n",
    "        finalresidue = self.final(torch.concat(residues, dim = -1)) \n",
    "        return enc + finalresidue      \n",
    "\n",
    "\n",
    "class RaygunDecoder(nn.Module):\n",
    "    def __init__(self, dim = 1280, numdecoders = 5, convkernel = 7,\n",
    "                 nhead = 20, dropout = 0.1, activation = \"gelu\"):\n",
    "        super(RaygunDecoder, self).__init__()\n",
    "        self.dbefore = nn.ModuleList()\n",
    "         \n",
    "        for i in range(numdecoders):\n",
    "            self.dbefore.append(Block(dim = dim,\n",
    "                                      convkernel = convkernel,\n",
    "                                      attnheads = nhead,\n",
    "                                      ))\n",
    "\n",
    "        self.repetition = Repetition()\n",
    "\n",
    "        self.dafter = nn.ModuleList()\n",
    "        for i in range(numdecoders+1):\n",
    "            self.dafter.append(Block(dim = dim,\n",
    "                                      convkernel = convkernel, \n",
    "                                      attnheads = nhead, \n",
    "                                      ))\n",
    "        self.final = nn.Sequential(\n",
    "                            nn.Linear(dim * (numdecoders+2), dim // (numdecoders+2) * 4),\n",
    "                            nn.SiLU(),\n",
    "                            nn.Linear(dim // (numdecoders+2) * 4, dim)\n",
    "                        )\n",
    "\n",
    "    def forward(self, encoding, finallengths, mask = None):\n",
    "        \"\"\"\n",
    "        Decoder is entirely deterministic. No noise added here.\n",
    "        \"\"\"\n",
    "        out = self.repetition(encoding, finallengths)\n",
    "        # construct different encoding replicates\n",
    "        ereplicates = []\n",
    "        ereplicates.append(encoding)\n",
    "        for mod in self.dbefore:\n",
    "            encoding = encoding + mod(encoding, mask = mask)\n",
    "            ereplicates.append(encoding)\n",
    "        ## for each replicates, expand and apply model\n",
    "        outreplicates = [out]\n",
    "        for ereplicate, mod in zip(ereplicates, self.dafter):\n",
    "            outreplicates.append(mod(self.repetition(ereplicate, finallengths),\n",
    "                                    mask = mask))\n",
    "        return out + self.final(torch.concat(outreplicates, dim = -1))\n",
    "\n",
    "class Raygun(nn.Module):\n",
    "    def __init__(self, dim = 1280, nhead = 20, convkernel = 7, \n",
    "                 numencoders = 10, numdecoders = 10,\n",
    "                 dropout = 0.1,\n",
    "                 reduction = 50, activation = \"gelu\",\n",
    "                 esmdecodertotokenfile = None, \n",
    "                 fixed_esm_batching=False):\n",
    "        super(Raygun, self).__init__()\n",
    "        self.encoder = RaygunEncoder(dim     = dim, \n",
    "                                reduction    = reduction, \n",
    "                                convkernel   = convkernel,\n",
    "                                numencoders  = numencoders, \n",
    "                                dropout      = dropout, \n",
    "                                activation   = activation,\n",
    "                                nhead        = nhead)\n",
    "        self.decoder = RaygunDecoder(dim     = dim, \n",
    "                                 nhead       = nhead, \n",
    "                                 convkernel  = convkernel,\n",
    "                                 numdecoders = numdecoders,\n",
    "                                 dropout     = dropout, \n",
    "                                 activation  = activation)\n",
    "\n",
    "        self.esmdecoder = DecoderBlock(dim = dim, \n",
    "                                      nhead = 20, \n",
    "                                      fixed_batching=fixed_esm_batching)\n",
    "        if esmdecodertotokenfile is not None:\n",
    "            checkpoint = torch.load(esmdecodertotokenfile)\n",
    "            self.esmdecoder.load_state_dict(checkpoint[\"model_state\"])\n",
    "            del checkpoint\n",
    "        self.alphtotoks  = {'<cls>': 0, '<pad>': 1, '<eos>': 2, '<unk>': 3, 'L': 4, 'A': 5, 'G': 6, 'V': 7, 'S': 8, 'E': 9, 'R': 10, 'T': 11, 'I': 12, 'D': 13, 'P': 14, 'K': 15, 'Q': 16, 'N': 17, 'F': 18, 'Y': 19, 'M': 20, 'H': 21, 'W': 22, 'C': 23, 'X': 24, 'B': 25, 'U': 26, 'Z': 27, 'O': 28, '.': 29, '-': 30, '<null_1>': 31, '<mask>': 32}\n",
    "        self.esmalphdict = {i:k for k, i in self.alphtotoks.items()}\n",
    "\n",
    "    def get_sequence_from_logits(self, logits, lengths):\n",
    "        batch, seq, _ = logits.shape\n",
    "        if batch == 1:\n",
    "            assert isinstance(lengths, int) or lengths.shape[0] == 1, \"batch=1 but multiple lengths provided\"\n",
    "            if isinstance(lengths, int):\n",
    "                lengths = [lengths]\n",
    "        else:\n",
    "            assert len(lengths.shape) == 1 and lengths.shape[0] == batch, \"batch size and `lengths` dimension should be the same\"\n",
    "        output_seqs   = []\n",
    "        with torch.no_grad():\n",
    "            for idx, length in enumerate(lengths):\n",
    "                logit   = logits[idx, :length, :]\n",
    "                ptokens = torch.argmax(logit, dim = -1).cpu().numpy().tolist()\n",
    "                pseqs   = \"\".join([self.esmalphdict[t] if t in set(range(4, 29)) else \"X\" \n",
    "                                  for t in ptokens])\n",
    "                output_seqs.append(pseqs)\n",
    "        return output_seqs\n",
    "\n",
    "    def get_sequences_from_fixed(self, fixedembs, lengths):\n",
    "        with torch.no_grad():\n",
    "            out    = self.decoder(fixedembs, lengths)\n",
    "            logits = self.esmdecoder(out)\n",
    "        return self.get_sequence_from_logits(logits, lengths)\n",
    "    \n",
    "    def forward(self, x, mask = None, \n",
    "                target_lengths = None, \n",
    "                noise = None, \n",
    "                token = None, \n",
    "                return_logits_and_seqs = False):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        x    -> [batch, seq, dim]: ESM-2 650M embedding\n",
    "        mask -> [batch, seq]: Binary matrix. Suppose the sequence length of a  `batch_id` is `n`. Then mask[batch_id] should be such that mask[batch_id, :n] = 1 and mask[batch_id, n:] = 0  \n",
    "        output_lengths -> [batch]: target length\n",
    "        \"\"\"\n",
    "        batch, length_, dim = x.shape\n",
    "        if target_lengths is not None:\n",
    "            assert target_lengths.shape[0] == batch, \"`output_lengths` should be a 1d tensor, its dimension should match the batch size\"\n",
    "            lengths = target_lengths\n",
    "        elif batch == 1:\n",
    "            lengths = length_  \n",
    "        else:\n",
    "            assert mask is not None, \"batch larger than 1 but mask is Null\"\n",
    "            lengths = mask.sum(dim = -1)\n",
    "        mem = self.encoder(x, mask = mask, noise = noise)\n",
    "        out = self.decoder(mem, lengths)\n",
    "        \n",
    "        result = {\"fixed_length_embedding\": mem, \n",
    "                 \"reconstructed_embedding\": out}\n",
    "        \n",
    "        if token is not None or return_logits_and_seqs:\n",
    "            logits          = self.esmdecoder(out) #batch, seq, token\n",
    "            result[\"logits\"] = logits\n",
    "            \n",
    "        if token is not None:\n",
    "            if len(token.shape) == 3:\n",
    "                tok   = rearrange(token, \"b h k -> (b h k)\")\n",
    "            else:\n",
    "                tok   = rearrange(token, \"b k -> (b k)\")\n",
    "            loss      = F.cross_entropy(rearrange(logits, \"b h k -> (b h) k\"), \n",
    "                                        tok, ignore_index = 1)\n",
    "            result[\"ce_loss\"] = loss\n",
    "        if return_logits_and_seqs:\n",
    "            result[\"generated-sequences\"] = self.get_sequence_from_logits(logits, lengths)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1853a2-9087-4ef4-94b3-17472098f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dustbin or consideration code: \n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def custom_anti_pool1d(x_mean, desired_output_size):\n",
    "    # x_mean shape: (B, C, L_in)\n",
    "    B, C, L_in = x_mean.shape\n",
    "    L_out = desired_output_size\n",
    "\n",
    "    ratio = L_out / L_in\n",
    "    N_rep = int(torch.floor(torch.tensor(ratio)))  # Integer replication factor (e.g., 4)\n",
    "    F_blend = ratio - N_rep                       # Fractional blend factor (e.g., 0.5)\n",
    "\n",
    "    if N_rep == 0:\n",
    "        # Fallback if the ratio is < 1 (e.g., use linear interpolation for reduction)\n",
    "        return F.interpolate(x_mean, size=L_out, mode='linear')\n",
    "    \n",
    "    # --- Step 1: Nearest-Neighbor-like Replication (L_in * N_rep) ---\n",
    "    # F.interpolate with mode='nearest' and a scale_factor is efficient for replication\n",
    "    x_replicate = F.interpolate(\n",
    "        input=x_mean,\n",
    "        scale_factor=N_rep,\n",
    "        mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Target length after replication: L_rep = L_in * N_rep\n",
    "\n",
    "    # --- Step 2: Calculate Boundary Values ---\n",
    "    # Boundary values are calculated between consecutive elements: (x_{i} * F_blend) + (x_{i+1} * (1 - F_blend))\n",
    "    # Note: Since your example used (1/2x + 1/2y), F_blend should be interpreted as the weight of the *next* element.\n",
    "    # We will use F_blend as the weight of the *current* element for consistency with standard weighted average for a boundary:\n",
    "    # Blend = (x_i * (1 - F_blend)) + (x_{i+1} * F_blend)\n",
    "    # If F_blend = 0.5, this is simply (x_i + x_{i+1}) / 2\n",
    "\n",
    "    # Shift tensor to get x_{i+1}\n",
    "    x_shifted = torch.roll(x_mean, shifts=-1, dims=-1)\n",
    "    \n",
    "    # Boundary values (for all L_in - 1 boundaries)\n",
    "    # e.g., for i=0: (x_0 * (1 - F_blend)) + (x_1 * F_blend)\n",
    "    boundary_values = (x_mean * (1 - F_blend)) + (x_shifted * F_blend)\n",
    "    \n",
    "    # We only need L_in - 1 boundary values (last one is irrelevant as it's the boundary after the last element)\n",
    "    boundary_values = boundary_values[..., :-1] \n",
    "    \n",
    "    # --- Step 3: Interleave Replication and Boundary Values ---\n",
    "    \n",
    "    # Pre-allocate the final tensor of size (B, C, L_out)\n",
    "    x_upscale = torch.zeros(B, C, L_out, device=x_mean.device, dtype=x_mean.dtype)\n",
    "    \n",
    "    # Indices for the start of each block: 0, N_rep, 2*N_rep, ...\n",
    "    # Indices for the boundary values: N_rep, 2*N_rep, 3*N_rep, ...\n",
    "    \n",
    "    for i in range(L_in - 1):\n",
    "        # Place the replicated block (x_i, x_i, ..., x_i)\n",
    "        start_idx = i * (N_rep + 1)\n",
    "        x_upscale[..., start_idx : start_idx + N_rep] = x_replicate[..., i * N_rep : (i + 1) * N_rep]\n",
    "        \n",
    "        # Place the boundary value\n",
    "        boundary_idx = start_idx + N_rep\n",
    "        x_upscale[..., boundary_idx] = boundary_values[..., i]\n",
    "\n",
    "    # --- Step 4: Handle the Final Block ---\n",
    "    # The last block has no boundary value after it, only the replicated values.\n",
    "    # The last block starts at (L_in - 1) * (N_rep + 1)\n",
    "    last_block_start = (L_in - 1) * (N_rep + 1)\n",
    "    # The replicated part of the last element starts at (L_in - 1) * N_rep in x_replicate\n",
    "    last_rep_start = (L_in - 1) * N_rep\n",
    "    \n",
    "    x_upscale[..., last_block_start : L_out] = x_replicate[..., last_rep_start : last_rep_start + (L_out - last_block_start)]\n",
    "\n",
    "    return x_upscale\n",
    "\n",
    "# Example Usage:\n",
    "x_mean = torch.tensor([[[10.0, 20.0]]]) # L_in = 2, x=10.0, y=20.0\n",
    "desired_output_size = 9 # L_out = 9, Ratio = 4.5\n",
    "\n",
    "x_upscale_custom = custom_anti_pool1d(x_mean, desired_output_size)\n",
    "print(x_upscale_custom)\n",
    "\n",
    "# Desired output: [10.0, 10.0, 10.0, 10.0, 15.0, 20.0, 20.0, 20.0, 20.0]\n",
    "# Where 15.0 is (10.0 + 20.0)/2\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raygun",
   "language": "python",
   "name": "raygun"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
