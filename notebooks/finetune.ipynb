{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2abaaa7b-c866-4cc3-96e1-949713ad1aeb",
   "metadata": {},
   "source": [
    "## Load a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a1e05e8-5e48-42f1-b132-87729f167ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from raygun.pretrained import raygun_2_2mil_800M\n",
    "# \n",
    "raymodel = raygun_2_2mil_800M(return_lightning_module=True) ## must set return_lightning_module to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "865d36b0-63b8-4689-ab67-d649b4e967e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esm.pretrained import esm2_t33_650M_UR50D\n",
    "model, alph = esm2_t33_650M_UR50D()\n",
    "model       = model.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4afcc474-7ec5-4662-a316-c2a238c47513",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RaygunLightning(\n",
       "  (model): Raygun(\n",
       "    (encoder): RaygunEncoder(\n",
       "      (encoders): ModuleList(\n",
       "        (0-11): 12 x Block(\n",
       "          (encoder): TransformerLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (rot_emb): RotaryEmbedding()\n",
       "            )\n",
       "            (self_attn_layer_norm): ESM1LayerNorm()\n",
       "            (fc1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "            (fc2): Linear(in_features=2560, out_features=1280, bias=True)\n",
       "            (final_layer_norm): ESM1LayerNorm()\n",
       "          )\n",
       "          (convblock): ConvBlock(\n",
       "            (c1): ConvMasked(\n",
       "              (conv): Conv1d(1280, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
       "            )\n",
       "            (s1): SiLU()\n",
       "            (c2): ConvMasked(\n",
       "              (conv): Conv1d(640, 320, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "            )\n",
       "            (s2): SiLU()\n",
       "            (c3): ConvMasked(\n",
       "              (conv): Conv1d(320, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
       "            )\n",
       "            (s3): SiLU()\n",
       "          )\n",
       "          (final): Linear(in_features=640, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (reduction): Reduction()\n",
       "      (final): Sequential(\n",
       "        (0): Linear(in_features=16640, out_features=392, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=392, out_features=1280, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): RaygunDecoder(\n",
       "      (dbefore): ModuleList(\n",
       "        (0-11): 12 x Block(\n",
       "          (encoder): TransformerLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (rot_emb): RotaryEmbedding()\n",
       "            )\n",
       "            (self_attn_layer_norm): ESM1LayerNorm()\n",
       "            (fc1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "            (fc2): Linear(in_features=2560, out_features=1280, bias=True)\n",
       "            (final_layer_norm): ESM1LayerNorm()\n",
       "          )\n",
       "          (convblock): ConvBlock(\n",
       "            (c1): ConvMasked(\n",
       "              (conv): Conv1d(1280, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
       "            )\n",
       "            (s1): SiLU()\n",
       "            (c2): ConvMasked(\n",
       "              (conv): Conv1d(640, 320, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "            )\n",
       "            (s2): SiLU()\n",
       "            (c3): ConvMasked(\n",
       "              (conv): Conv1d(320, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
       "            )\n",
       "            (s3): SiLU()\n",
       "          )\n",
       "          (final): Linear(in_features=640, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (repetition): Repetition()\n",
       "      (dafter): ModuleList(\n",
       "        (0-12): 13 x Block(\n",
       "          (encoder): TransformerLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (rot_emb): RotaryEmbedding()\n",
       "            )\n",
       "            (self_attn_layer_norm): ESM1LayerNorm()\n",
       "            (fc1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "            (fc2): Linear(in_features=2560, out_features=1280, bias=True)\n",
       "            (final_layer_norm): ESM1LayerNorm()\n",
       "          )\n",
       "          (convblock): ConvBlock(\n",
       "            (c1): ConvMasked(\n",
       "              (conv): Conv1d(1280, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
       "            )\n",
       "            (s1): SiLU()\n",
       "            (c2): ConvMasked(\n",
       "              (conv): Conv1d(640, 320, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "            )\n",
       "            (s2): SiLU()\n",
       "            (c3): ConvMasked(\n",
       "              (conv): Conv1d(320, 640, kernel_size=(7,), stride=(1,), padding=valid)\n",
       "            )\n",
       "            (s3): SiLU()\n",
       "          )\n",
       "          (final): Linear(in_features=640, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (final): Sequential(\n",
       "        (0): Linear(in_features=17920, out_features=364, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=364, out_features=1280, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (esmdecoder): DecoderBlock(\n",
       "      (encoder): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (rot_emb): RotaryEmbedding()\n",
       "        )\n",
       "        (self_attn_layer_norm): ESM1LayerNorm()\n",
       "        (fc1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "        (fc2): Linear(in_features=2560, out_features=1280, bias=True)\n",
       "        (final_layer_norm): ESM1LayerNorm()\n",
       "      )\n",
       "      (final): Sequential(\n",
       "        (0): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): Linear(in_features=320, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decodermodel): DecoderBlock(\n",
       "    (encoder): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): ESM1LayerNorm()\n",
       "      (fc1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "      (fc2): Linear(in_features=2560, out_features=1280, bias=True)\n",
       "      (final_layer_norm): ESM1LayerNorm()\n",
       "    )\n",
       "    (final): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=320, bias=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=320, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raymodel.to(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e0b99c-dc50-4e79-a5b3-1a8b352aedb1",
   "metadata": {},
   "source": [
    "## Before finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391494a6-f629-4d65-afd6-428c58061dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from raygun.modelv2.training import training\n",
    "from Bio import SeqIO\n",
    "import random\n",
    "from io import StringIO\n",
    "trainfasta = \"../data/fastas/human-mouse.sprot.fasta\"\n",
    "recs       = list(SeqIO.parse(trainfasta, \"fasta\"))\n",
    "recs       = [r for r in recs if len(r.seq) > 50 and len(r.seq) < 1000]\n",
    "recs       = random.sample(recs, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "387f5341-54e5-438c-8613-13dbe4ecf823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raygun.modelv2.loader import RaygunData\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm \n",
    "recseq = \"\"\n",
    "for r in recs:\n",
    "    recseq     += f\"\"\">{r.id}\n",
    "{str(r.seq)}\n",
    "\"\"\"\n",
    "fastafile  = StringIO(recseq)\n",
    "preddata   = RaygunData(fastafile, \n",
    "                        alph, model, device = 0)\n",
    "## use the collatefn provided in RaygunData\n",
    "predloader = DataLoader(preddata, shuffle = True, \n",
    "                       batch_size = 3, collate_fn=preddata.collatefn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f6b346f-8919-480e-8322-6e52a82b604b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Before finetuning: 100%|██████████| 34/34 [00:18<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "true_seqs = []\n",
    "pred_seqs = []\n",
    "for tok, emb, mask, bat in tqdm(predloader, desc = \"Before finetuning\"):\n",
    "    tok = tok.to(0)\n",
    "    emb = emb.to(0)\n",
    "    mask = mask.to(0)\n",
    "    _, ts = zip(*bat)\n",
    "    true_seqs += ts\n",
    "    ## set `return_logits_and_seqs` to true for the model to return `generated-sequences`. \n",
    "    ## use `error_c` to determine the amount of noise to be added while generating.\n",
    "    results = raymodel.model(emb, mask=mask, noise = 0., \n",
    "                       return_logits_and_seqs = True)\n",
    "    pred_seqs += results[\"generated-sequences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68b84896-71b5-4643-b616-084b0032bbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9148910088045968"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def compute_seq_id(s1, s2):\n",
    "    return np.average([1 if x == y else 0 for x, y in zip(list(s1),\n",
    "                                             list(s2))])\n",
    "seqdata     = [(tr, orig, compute_seq_id(tr, orig)) for tr, orig in zip(true_seqs, pred_seqs)]\n",
    "_,_, seqids = zip(*seqdata)\n",
    "np.mean(seqids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db95fe66-9914-49cf-b89b-c073f45f540e",
   "metadata": {},
   "source": [
    "## Perform finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b283a718-bd4b-406e-88ab-cbb32f73387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raygun.modelv2.ltraygun import RaygunLightning\n",
    "from torch.utils.data import DataLoader\n",
    "from raygun.modelv2.loader import RaygunData\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from pathlib import Path\n",
    "import os\n",
    "def training_(ltmodel, esmmodel, esmalphabet, \n",
    "             trainfasta, validfasta, outfld, \n",
    "             devices=1, clip=0.001, lr=1e-4, \n",
    "             epoch=5, batchsize=2, finetune=True,\n",
    "             delete_checkpoint_after_loading = True):\n",
    "    def is_notebook():\n",
    "        \"\"\"\n",
    "        needed for ddp strategy\n",
    "        \"\"\"\n",
    "        try:\n",
    "            shell = get_ipython().__class__.__name__\n",
    "            return shell == \"ZMQInteractiveShell\"\n",
    "        except NameError:\n",
    "            return False\n",
    "    Path(outfld).mkdir(exist_ok=True)\n",
    "    ltmodel.lr          = lr\n",
    "    ltmodel.finetune    = finetune\n",
    "    ## starting epoch\n",
    "    ltmodel.epoch       = 0\n",
    "    ltmodel.traininglog = f\"{outfld}/traininglog.txt\"\n",
    "    ltmodel.log_wandb   = False\n",
    "    \n",
    "    ## train loaders\n",
    "    traindata = RaygunData(fastafile    = trainfasta,\n",
    "                           alphabet     = esmalphabet,\n",
    "                           model        = esmmodel, \n",
    "                           device       = 0)\n",
    "    trainloader = DataLoader(traindata, \n",
    "                             shuffle    = False, \n",
    "                             batch_size = batchsize,\n",
    "                             collate_fn = traindata.collatefn)\n",
    "    ## validation loaders\n",
    "    validdata = RaygunData(fastafile    = validfasta,\n",
    "                           alphabet     = esmalphabet,\n",
    "                           model        = esmmodel,\n",
    "                           device       = 0)\n",
    "    validloader = DataLoader(validdata, \n",
    "                            shuffle    = False,\n",
    "                            batch_size = batchsize, \n",
    "                            collate_fn = validdata.collatefn)\n",
    "    \n",
    "    chk_callback = ModelCheckpoint(\n",
    "                        monitor           = \"val_blosum_ratio\",\n",
    "                        mode              = \"max\",\n",
    "                        save_top_k        = 1, \n",
    "                        save_weights_only = True, \n",
    "                        dirpath           = outfld,\n",
    "                        filename          = \"model-{epoch:02d}-{step:06d}-{val_blosum_ratio:.4f}\",\n",
    "                        save_on_train_epoch_end = True)\n",
    "\n",
    "    if is_notebook():\n",
    "        trainer = L.Trainer(accumulate_grad_batches = 2,\n",
    "                            callbacks = [chk_callback],\n",
    "                            accelerator             = \"gpu\", \n",
    "                            devices                 = 1, \n",
    "                            max_epochs              = epoch, \n",
    "                            gradient_clip_val       = clip,\n",
    "                            gradient_clip_algorithm = \"value\")\n",
    "    else:\n",
    "        trainer = L.Trainer(accumulate_grad_batches = 2,\n",
    "                            callbacks = [chk_callback],\n",
    "                            accelerator             = \"gpu\", \n",
    "                            devices                 = devices, \n",
    "                            strategy                = \"ddp\",\n",
    "                            max_epochs              = epoch, \n",
    "                            gradient_clip_val       = clip,\n",
    "                            gradient_clip_algorithm = \"value\")\n",
    "    trainer.fit(ltmodel.to(0), \n",
    "                trainloader, \n",
    "                validloader)\n",
    "    chkptloc = [ckpt for ckpt in Path(outfld).iterdir() \n",
    "               if ckpt.suffix == \".ckpt\"][0]\n",
    "    \n",
    "    new_checkpoint = torch.load(chkptloc, weights_only=True)[\"state_dict\"]\n",
    "    if delete_checkpoint_after_loading:\n",
    "        os.remove(chkptloc)\n",
    "    \n",
    "    return new_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "426f5bba-d5db-478f-9e87-4847e3445a8c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/hpc/group/singhlab/user/kd312/minimamba/envs/molfeat/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /hpc/group/singhlab/user/kd312/projects/raygunv2/src/raygun-new-publication/raygun/notebooks/finetuned-output exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/hpc/group/singhlab/user/kd312/minimamba/envs/molfeat/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/hpc/group/singhlab/user/kd312/minimamba/envs/molfeat/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py:258: Found unsupported keys in the lr scheduler dict: {'freq'}. HINT: remove them from the output of `configure_optimizers`.\n",
      "\n",
      "  | Name         | Type         | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model        | Raygun       | 831 M  | train\n",
      "1 | decodermodel | DecoderBlock | 13.5 M | train\n",
      "------------------------------------------------------\n",
      "831 M     Trainable params\n",
      "0         Non-trainable params\n",
      "831 M     Total params\n",
      "3,326.035 Total estimated model params size (MB)\n",
      "883       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55eb4e59e2ce4d2c8c76585c276bba45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/singhlab/user/kd312/minimamba/envs/molfeat/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485326fb4c0948eb88397ee8c7aafaf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111054de11ff414e94c4cc0dc49816b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74370c5315764e02baa58560f9bd70ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e775ffae5f4f74a6301baab96422b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ee1abc6da44749b189811e6b61aa1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47fe7a6a8c040849e145ef0e7ae4db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "new_checkpoint = training_(raymodel, model, alph,\n",
    "                           StringIO(recseq), StringIO(recseq),\n",
    "                           \"finetuned-output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e07fe14-b3aa-4876-8440-9b261dce8ec3",
   "metadata": {},
   "source": [
    "## After finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52c52a53-28f3-42cd-9232-a7edd24034e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raymodel.load_state_dict(new_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e8650f5-2abb-4f6a-99cd-cdd9bfef6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from raygun.modelv2.loader import RaygunData\n",
    "\n",
    "fastafile  = StringIO(recseq)\n",
    "preddata   = RaygunData(fastafile, \n",
    "                        alph, model, device = 0)\n",
    "## use the collatefn provided in RaygunData\n",
    "predloader = DataLoader(preddata, shuffle = True, \n",
    "                       batch_size = 3, collate_fn=preddata.collatefn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16531dbb-c6f6-44d0-a099-7ba5116d96ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "raymodel = raymodel.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c04e32c3-445b-4e7c-b181-ec689f872ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "After finetuning: 100%|██████████| 34/34 [00:17<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "true_seqs = []\n",
    "pred_seqs = []\n",
    "for tok, emb, mask, bat in tqdm(predloader, desc = \"After finetuning\"):\n",
    "    tok = tok.to(0)\n",
    "    emb = emb.to(0)\n",
    "    mask = mask.to(0)\n",
    "    _, ts = zip(*bat)\n",
    "    true_seqs += ts\n",
    "    ## set `return_logits_and_seqs` to true for the model to return `generated-sequences`. \n",
    "    ## use `error_c` to determine the amount of noise to be added while generating.\n",
    "    results = raymodel.model(emb, mask=mask, noise = 0.1, \n",
    "                       return_logits_and_seqs = True)\n",
    "    pred_seqs += results[\"generated-sequences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bdbdc0a-59a6-4850-ae4c-2d5fb0c927a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.963639790354421"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "seqids = [compute_seq_id(tr, orig) for tr, orig in zip(true_seqs, pred_seqs)]\n",
    "np.mean(seqids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7f8a6ab-3740-4a3b-913d-f5d3eed365d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../example-sh/ALL.fasta\", \"w\") as of:\n",
    "    of.write(recseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb0bc7-f53a-4483-8809-c823da21de4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molfeat",
   "language": "python",
   "name": "molfeat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
